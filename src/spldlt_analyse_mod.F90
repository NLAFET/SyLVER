!> @file
!> @copyright 2016- The Science and Technology Facilities Council (STFC)
!> @author    Jonathan Hogg
!> @author    Florent Lopez
module spldlt_analyse_mod
  use, intrinsic :: iso_c_binding
  use spral_ssids_akeep, only: ssids_akeep 
  use spral_ssids_cpu_iface ! fixme only
  use spral_ssids_datatypes
  use spral_hw_topology, only: numa_region
  use sylver_inform_mod
  implicit none

  !
  ! Data type for information generated in analyse phase
  !
  type spldlt_akeep_type
     ! Analyse information generated by SPRAL
     type(ssids_akeep) :: akeep
     ! C ptr on symbolic tree
     type(c_ptr) :: symbolic_tree_c
     ! Number of subtrees
     integer :: nsubtrees
     ! Root of each subtrees
     integer, dimension(:), allocatable :: subtree_en
     ! Inform at end of analyse phase
     type(sylver_inform) :: inform
   contains
      procedure, pass(spldlt_akeep) :: free => akeep_free
  end type spldlt_akeep_type

  interface spldlt_create_symbolic_tree_c
     ! type(c_ptr) function spldlt_create_symbolic_tree(akeep, n, nnodes, & 
     !      sptr, sparent, rptr, rlist, nptr, nlist, nparts, part, &
     !      contrib_idx, exec_loc, contrib_dest, options) &
     !      bind(C, name="spldlt_create_symbolic_tree")
     !   use, intrinsic :: iso_c_binding
     !   import :: cpu_factor_options
     !   implicit none
     !   type(c_ptr), value :: akeep
     !   integer(c_int), value :: n
     !   integer(c_int), value :: nnodes
     !   integer(c_int), dimension(*), intent(in) :: sptr
     !   integer(c_int), dimension(*), intent(in) :: sparent
     !   integer(c_long), dimension(*), intent(in) :: rptr
     !   integer(c_int), dimension(*), intent(in) :: rlist
     !   integer(c_long), dimension(*), intent(in) :: nptr
     !   integer(c_long), dimension(2, *), intent(in) :: nlist
     !   integer(C_INT), value :: nparts
     !   integer(C_INT), dimension(*), intent(in) :: part
     !   integer(C_INT), dimension(*), intent(in) :: contrib_idx
     !   integer(C_INT), dimension(*), intent(in) :: exec_loc
     !   integer(C_INT), dimension(*), intent(in) :: contrib_dest
     !   type(cpu_factor_options), intent(in) :: options
     ! end function spldlt_create_symbolic_tree

     ! Debug
     type(c_ptr) function spldlt_create_symbolic_tree( &
          akeep, n, nnodes, sptr, sparent, rptr, rlist, nptr, nlist, &
          nsubtrees, subtrees, small, contrib_dest, exec_loc) &
          ! nparts, part, contrib_idx, exec_loc, contrib_dest) &
          bind(C, name="spldlt_create_symbolic_tree")
       use, intrinsic :: iso_c_binding
       implicit none
       type(c_ptr), value :: akeep
       integer(c_int), value :: n
       integer(c_int), value :: nnodes
       integer(c_int), dimension(*), intent(in) :: sptr
       integer(c_int), dimension(*), intent(in) :: sparent
       integer(c_long), dimension(*), intent(in) :: rptr
       integer(c_int), dimension(*), intent(in) :: rlist
       integer(c_long), dimension(*), intent(in) :: nptr
       integer(c_long), dimension(2, *), intent(in) :: nlist
       integer(c_int), value :: nsubtrees
       integer(c_int), dimension(*), intent(in) :: subtrees
       integer(c_int), dimension(*), intent(in) :: small
       integer(c_int), dimension(*), intent(in) :: contrib_dest
       integer(c_int), dimension(*), intent(in) :: exec_loc
       ! integer(c_int), value :: nparts
       ! integer(c_int), dimension(*), intent(in) :: part
       ! integer(c_int), dimension(*), intent(in) :: contrib_idx
       ! integer(c_int), dimension(*), intent(in) :: exec_loc
       ! integer(c_int), dimension(*), intent(in) :: contrib_dest
     end function spldlt_create_symbolic_tree

  end interface spldlt_create_symbolic_tree_c

contains

  subroutine akeep_free(spldlt_akeep)
    implicit none

    class(spldlt_akeep_type), intent(inout) :: spldlt_akeep

    integer :: flag

    call spldlt_akeep%akeep%free(flag)

    if (allocated(spldlt_akeep%subtree_en)) deallocate(spldlt_akeep%subtree_en)
    
  end subroutine akeep_free
  
  !> @brief Release memory and cleanup data structure
  subroutine spldlt_akeep_free(spldlt_akeep)
    implicit none

    type(spldlt_akeep_type), intent(inout) :: spldlt_akeep

    call spldlt_akeep%free()

  end subroutine spldlt_akeep_free  
  
  ! Debug
  ! subroutine allocate_cpu_symbolic_subtree()
  !   implicit none
  !   class(cpu_symbolic_subtree), pointer :: this
  ! end subroutine allocate_cpu_symbolic_subtree

  !****************************************************************************
  !
  ! Build a map from A to nodes
  ! lcol( nlist(2,i) ) = val( nlist(1,i) )
  ! nptr defines start of each node in nlist
  !
  ! Note: routine from SSIDS

  subroutine build_map(n, ptr, row, perm, invp, nnodes, sptr, rptr, rlist, &
       nptr, nlist, st)
    implicit none
    ! Original matrix A
    integer, intent(in) :: n
    integer(long), dimension(n+1), intent(in) :: ptr
    integer, dimension(ptr(n+1)-1), intent(in) :: row
    ! Permutation and its inverse (some entries of perm may be negative to
    ! act as flags for 2x2 pivots, so need to use abs(perm))
    integer, dimension(n), intent(in) :: perm
    integer, dimension(n), intent(in) :: invp
    ! Supernode partition of L
    integer, intent(in) :: nnodes
    integer, dimension(nnodes+1), intent(in) :: sptr
    ! Row indices of L
    integer(long), dimension(nnodes+1), intent(in) :: rptr
    integer, dimension(rptr(nnodes+1)-1), intent(in) :: rlist
    ! Output mapping
    integer(long), dimension(nnodes+1), intent(out) :: nptr
    integer(long), dimension(2, ptr(n+1)-1), intent(out) :: nlist
    ! Error check paramter
    integer, intent(out) :: st

    integer :: i, j, k
    integer(long) :: ii, jj, pp
    integer :: blkm
    integer :: col
    integer :: node
    integer, dimension(:), allocatable :: ptr2, row2
    integer(long), dimension(:), allocatable :: origin
    integer, dimension(:), allocatable :: map

    allocate(map(n), ptr2(n+3), row2(ptr(n+1)-1), origin(ptr(n+1)-1), stat=st)
    if (st .ne. 0) return

    !
    ! Build transpose of A in ptr2, row2. Store original posn of entries in
    ! origin array.
    !
    ! Count number of entries in row i in ptr2(i+2). Don't include diagonals.
    ptr2(:) = 0
    do i = 1, n
       do jj = ptr(i), ptr(i+1)-1
          k = row(jj)
          if (k .eq. i) cycle
          ptr2(k+2) = ptr2(k+2) + 1
       end do
    end do
    ! Work out row starts such that row i starts in posn ptr2(i+1)
    ptr2(1:2) = 1
    do i = 1, n
       ptr2(i+2) = ptr2(i+2) + ptr2(i+1)
    end do
    ! Drop entries into place
    do i = 1, n
       do jj = ptr(i), ptr(i+1)-1
          k = row(jj)
          if (k .eq. i) cycle
          row2(ptr2(k+1)) = i
          origin(ptr2(k+1)) = jj
          ptr2(k+1) = ptr2(k+1) + 1
       end do
    end do

    !
    ! Build nptr, nlist map
    !
    pp = 1
    do node = 1, nnodes
       blkm = int(rptr(node+1) - rptr(node))
       nptr(node) = pp

       ! Build map for node indices
       do jj = rptr(node), rptr(node+1)-1
          map(rlist(jj)) = int(jj-rptr(node)+1)
       end do

       ! Build nlist from A-lower transposed
       do j = sptr(node), sptr(node+1)-1
          col = invp(j)
          do i = ptr2(col), ptr2(col+1)-1
             k = abs(perm(row2(i))) ! row of L
             if (k .lt. j) cycle
             nlist(2,pp) = (j-sptr(node))*blkm + map(k)
             nlist(1,pp) = origin(i)
             pp = pp + 1
          end do
       end do

       ! Build nlist from A-lower
       do j = sptr(node), sptr(node+1)-1
          col = invp(j)
          do ii = ptr(col), ptr(col+1)-1
             k = abs(perm(row(ii))) ! row of L
             if (k .lt. j) cycle
             nlist(2,pp) = (j-sptr(node))*blkm + map(k)
             nlist(1,pp) = ii
             pp = pp + 1
          end do
       end do
    end do
    nptr(nnodes+1) = pp
  end subroutine build_map

  !> @brief Return the GPU device index associated with subtree
  !> p. Return -1 if subtree is mapped to a NUMA node
  !> @param cakeep C pointer on akeep structure
  !> @param p Subtree index
  integer(c_int) function subtree_get_devid_c(cakeep, p_c) bind(C)
    use, intrinsic :: iso_c_binding

    type(c_ptr), value :: cakeep
    integer(c_int), value :: p_c

    type(spldlt_akeep_type), pointer :: akeep => null() ! spldlt akeep structure 
    integer :: p
    integer :: nth
    integer :: loc
    integer :: device
    
    call c_f_pointer(cakeep, akeep)

    p = p_c+1 ! p_c is zero-indexed
    
#if defined(SPLDLT_USE_STARPU) && defined(SPLDLT_USE_OMP)
    ! Set the number of CPU regions
    
    ! nth = 2 ! FIXME Use number of NUMA sockets
    ! nth = 1 ! FIXME Use number of NUMA sockets

    ! Number of CPU region is equal to the number of NUMA nodes
    nth = size(akeep%akeep%topology, 1)

    loc = akeep%akeep%subtree(p)%exec_loc
    if (loc.le.nth) then
       device = -1
    else
       device = (loc-1) / nth
       device = device - 1
    end if
    ! print *, "[subtree_get_devid_c] subtree = ", p , ", loc = ", loc, ", nth = ", nth, ", device = ", device

    subtree_get_devid_c = device

#else
    !
    ! Assume flat topology
    !

    nth = akeep%akeep%topology(1)%nproc
    
    loc = akeep%akeep%subtree(p)%exec_loc
    if (loc.le.nth) then
       device = -1
    else
       device = loc-nth
       device = device - 1
    end if
    print *, "[subtree_get_devid_c] subtree = ", p , ", loc = ", loc, ", nth = ", nth, ", device = ", device

    subtree_get_devid_c = device

#endif
    
  end function subtree_get_devid_c


!****************************************************************************

!
! This routine requires the LOWER and UPPER triangular parts of A
! to be held in CSC format using ptr2 and row2
! AND lower triangular part held using ptr and row.
!
! On exit from this routine, order is set to order
! input to factorization.
!
  subroutine analyse_core(spldlt_akeep, n, ptr, row, ptr2, row2, order, invp, &
       options, inform)
    use spral_core_analyse, only : basic_analyse
    use spral_ssids_cpu_subtree, only : construct_cpu_symbolic_subtree
#if defined(SPLDLT_USE_GPU)
    use spral_ssids_gpu_subtree, only : construct_gpu_symbolic_subtree
#endif
    use sylver_datatypes_mod, only: sylver_options, set_ssids_options
    implicit none

    type(spldlt_akeep_type), target, intent(inout) :: spldlt_akeep ! spldlt akeep structure 
    integer, intent(in) :: n ! order of system
    integer(long), intent(in) :: ptr(n+1) ! col pointers (lower triangle) 
    integer, intent(in) :: row(ptr(n+1)-1) ! row indices (lower triangle)
    integer(long), intent(in) :: ptr2(n+1) ! col pointers (whole matrix)
    integer, intent(in) :: row2(ptr2(n+1)-1) ! row indices (whole matrix)
    integer, dimension(n), intent(inout) :: order
      !  On exit, holds the pivot order to be used by factorization.
    integer, dimension(n), intent(out) :: invp 
      ! Work array. Used to hold inverse of order but
      ! is NOT set to inverse for the final order that is returned.
    type(sylver_options), target, intent(in) :: options
    type(sylver_inform), intent(inout) :: inform

    character(50)  :: context ! Procedure name (used when printing).
    type(ssids_akeep), pointer :: akeep ! SSIDS akeep structure
    type(ssids_options) :: ssids_opts ! SSIDS options 

    integer :: nemin, flag
    integer :: i, j
    integer(long) :: nz ! ptr(n+1)-1
    integer :: st

    type(c_ptr) :: cakeep
    ! Tree prunnig
    integer, dimension(:), allocatable :: small
    integer :: nth, ngpu
    integer, dimension(:), allocatable :: subtree_sa 
    integer, dimension(:), allocatable :: contrib_dest, exec_loc
    integer :: loc ! Region index
    integer :: device ! Device index
    integer :: op ! Printing
    integer, dimension(:), allocatable :: level
    integer :: blkm, blkn
    
    context = 'analyse_core'
    akeep => spldlt_akeep%akeep

    ! Init SSIDS options using SyLVER options
    call set_ssids_options(options, ssids_opts)

    ! Check nemin and set to default if out of range.
    nemin = options%nemin
    if (nemin .lt. 1) nemin = sylver_nemin_default

    ! Perform basic analysis so we can figure out subtrees we want to construct
    call basic_analyse(n, ptr2, row2, order, akeep%nnodes, akeep%sptr, &
         akeep%sparent, akeep%rptr,akeep%rlist,                        &
         nemin, flag, inform%stat, inform%num_factor, inform%num_flops)
    select case(flag)
    case(0)
       ! Do nothing
    case(-1)
       ! Allocation error
       inform%flag = SYLVER_ERROR_ALLOCATION
       return
    case(1)
       ! Zero row/column.
       inform%flag = SYLVER_WARNING_ANAL_SINGULAR
    case default
       ! Should never reach here
       inform%flag = SYLVER_ERROR_UNKNOWN
    end select

    ! set invp to hold inverse of order
    do i = 1,n
       invp(order(i)) = i
    end do
    ! any unused variables are at the end and so can set order for them
    do j = akeep%sptr(akeep%nnodes+1), n
       i = invp(j)
       order(i) = 0
    end do

    ! Build map from A to L in nptr, nlist
    nz = ptr(n+1) - 1
    allocate(akeep%nptr(n+1), akeep%nlist(2,nz), stat=st)
    if (st .ne. 0) go to 100
    call build_map(n, ptr, row, order, invp, akeep%nnodes, akeep%sptr, &
         akeep%rptr, akeep%rlist, akeep%nptr, akeep%nlist, st)
    if (st .ne. 0) go to 100

    ! FIXME Use total number of procs on each NUMA nodes
    nth = akeep%topology(1)%nproc 
    ngpu = size(akeep%topology(1)%gpus)
    ! print *, "gpus = ", akeep%topology(1)%gpus
    ! nth = 1 ! debug
    ! nth = 4 ! debug

    ! write(op, '(a)') context 
#if defined(SPLDLT_USE_STARPU) && defined(SPLDLT_USE_OMP)

    ! nth = 2 ! FIXME Use number of NUMA sockets
    ! nth = 1 ! Flat topology

    ! Number of CPU region is equal to the number of NUMA nodes
    nth = size(akeep%topology, 1)

#endif

    if(options%print_level .gt. 1) then
       print *, "[analyse_core] Number of CPU regions = ", nth
    end if
    
    ! Allocate structures and init for tree prunning
    allocate(small(akeep%nnodes+1))
    allocate(contrib_dest(akeep%nnodes+1))
    allocate(subtree_sa(akeep%nnodes+1))
    ! TODO Use temp array and copy result into subtree_en to save
    ! memory
    allocate(spldlt_akeep%subtree_en(akeep%nnodes+1))
    allocate(exec_loc(akeep%nnodes+1))
    
    spldlt_akeep%nsubtrees = 0
    small = 0
    contrib_dest = 0
    subtree_sa = 0
    spldlt_akeep%subtree_en = 0

    ! Init number of partitions in the etree
    inform%num_part = 0 

    if (options%prune_tree) then
       ! Sort out subtrees

#if defined(SPLDLT_USE_OMP)       
       call find_subtree_partition(akeep%nnodes, akeep%sptr, akeep%sparent,           &
            akeep%rptr, ssids_opts, akeep%topology, akeep%nparts, akeep%part,            &
            exec_loc, akeep%contrib_ptr, akeep%contrib_idx, contrib_dest, inform, st)
       if (st .ne. 0) go to 100

       if(options%print_level .gt. 1) then
          print *, "[analyse_core] nparts = ", akeep%nparts
          print *, "[analyse_core] part = ", akeep%part(1:akeep%nparts+1)
          print *, "[analyse_core] exec_loc = ", exec_loc(1:akeep%nparts)
          ! print *, " contrib_ptr = ", akeep%contrib_ptr(1:akeep%nparts+1)
          ! print *, " contrib_idx = ", akeep%contrib_idx(1:akeep%nparts)
          ! print *, " contrib_dest = ", contrib_dest(1:akeep%nparts)
       end if
          
       do i = 1, akeep%nparts
          if(options%print_level .gt. 1) print *, "[analyse_core] exec_loc(", i, ") = ", exec_loc(i) 
          if (exec_loc(i) .eq. -1) cycle
          spldlt_akeep%nsubtrees = spldlt_akeep%nsubtrees +1
          exec_loc(spldlt_akeep%nsubtrees) = exec_loc(i) 
          small(akeep%part(i):akeep%part(i+1)-1) =  -(akeep%part(i+1)-1)
          small(akeep%part(i+1)-1) =  1
          subtree_sa(spldlt_akeep%nsubtrees) = akeep%part(i)
          spldlt_akeep%subtree_en(spldlt_akeep%nsubtrees) = akeep%part(i+1)-1
       end do

       inform%num_part = akeep%nparts
#else

       call prune_tree(akeep%nnodes, akeep%sptr, akeep%sparent, akeep%rptr, &
            nth, ngpu, options%gpu_perf_coeff, &
            spldlt_akeep%nsubtrees, small, contrib_dest, subtree_sa, &
            spldlt_akeep%subtree_en, exec_loc)

       ! Count the number of subtree plus the root subtree
       inform%num_part = spldlt_akeep%nsubtrees+1

#endif              
    end if

    if(options%print_level .gt. 1) print *, "[analyse_core] nsubtrees = ", spldlt_akeep%nsubtrees
    ! print *, "[analyse_core] contrib_dest = ", contrib_dest(1:spldlt_akeep%nsubtrees)
    ! print *, "[analyse_core] subtrees = ", spldlt_akeep%subtree_en(1:spldlt_akeep%nsubtrees)
! #if defined(SPLDLT_USE_STARPU) && defined(SPLDLT_USE_OMP)
    ! print *, "[analyse_core] exec_loc = ", exec_loc(1:spldlt_akeep%nsubtrees)
! #endif
    ! dump atree in a dot file
    call spldlt_print_atree(akeep%nnodes, akeep%sptr, akeep%sparent, akeep%rptr, small, exec_loc)
    ! call spldlt_print_atree_part(akeep)
    
    ! Construct symbolic subtrees
    ! allocate(akeep%subtree(akeep%nparts))
    allocate(akeep%subtree(spldlt_akeep%nsubtrees))

    do i = 1, spldlt_akeep%nsubtrees
    
       ! akeep%subtree(i)%exec_loc = exec_loc(i)
       ! akeep%subtree(i)%exec_loc = 1
       ! if (akeep%subtree(i)%exec_loc .eq. -1) cycle
       loc = exec_loc(i)
       akeep%subtree(i)%exec_loc = loc
       ! print *, "loc = ", loc, ", nth = ", nth
       if(loc.le.nth) then ! nth is treated as the number of CPU regions
          ! CPU
          akeep%subtree(i)%ptr => construct_cpu_symbolic_subtree(akeep%n,   &
               subtree_sa(i), spldlt_akeep%subtree_en(i)+1,                              &
               !akeep%part(i), akeep%part(i+1),                              &
               akeep%sptr, akeep%sparent,                                   &
               akeep%rptr, akeep%rlist, akeep%nptr, akeep%nlist,            &
               ! contrib_dest(akeep%contrib_ptr(i):akeep%contrib_ptr(i+1)-1), &
               contrib_dest(1:0), &
               ssids_opts)
#if defined(SPLDLT_USE_GPU)
       else
          ! GPU
          ! device = mod(loc, nth)-1 ! device indexes are 0-indexed
          device = loc-nth-1 ! device indexes are 0-indexed
          ! if(options%print_level .gt. 1) print *, "subtree = ", i, ", loc = ", loc, ", device = ", device
          akeep%subtree(i)%ptr => construct_gpu_symbolic_subtree(device, &
               akeep%n, subtree_sa(i), spldlt_akeep%subtree_en(i)+1, &
               akeep%sptr, akeep%sparent, akeep%rptr, akeep%rlist, akeep%nptr, akeep%nlist, &
               ssids_opts)
#endif
       end if
    end do

    ! call C++ analyse routine
    ! call cpu_copy_options_in(options, coptions)

    cakeep = c_loc(akeep)

    spldlt_akeep%symbolic_tree_c = &
         spldlt_create_symbolic_tree_c(cakeep, akeep%n, akeep%nnodes, & 
         akeep%sptr, akeep%sparent, akeep%rptr, akeep%rlist, akeep%nptr, &
         akeep%nlist, spldlt_akeep%nsubtrees, spldlt_akeep%subtree_en, small, &
         contrib_dest, exec_loc)
         !akeep%nparts, akeep%part, akeep%contrib_idx, exec_loc, contrib_dest)

    ! Info
    allocate(level(akeep%nnodes+1), stat=st)
    if (st .ne. 0) go to 100
    level(akeep%nnodes+1) = 0
    inform%maxfront = 0
    inform%maxdepth = 0
    do i = akeep%nnodes, 1, -1
       blkn = akeep%sptr(i+1) - akeep%sptr(i) 
       blkm = int(akeep%rptr(i+1) - akeep%rptr(i))
       level(i) = level(akeep%sparent(i)) + 1
       inform%maxfront = max(inform%maxfront, blkn)
       inform%maxdepth = max(inform%maxdepth, level(i))
    end do
    deallocate(level, stat=st)
    if (st .ne. 0) go to 100
    inform%matrix_rank = akeep%sptr(akeep%nnodes+1)-1
    inform%num_sup = akeep%nnodes

    ! print *, "n =", akeep%n 
    ! print *, "matrix_rank =", inform%matrix_rank 
    ! print *, "akeep%matrix_rank =", akeep%inform%matrix_rank 
    ! akeep%inform%matrix_rank = inform%matrix_rank
    
    ! Clean memory
    deallocate(small)
    deallocate(contrib_dest)
    deallocate(subtree_sa)
    deallocate(exec_loc)

200 continue
    spldlt_akeep%inform = inform
    call inform%print_flag(options, context)
    return    
100 continue
    inform%stat = st
    if (inform%stat .ne. 0) then
       inform%flag = SYLVER_ERROR_ALLOCATION
    end if
    goto 200
    
  end subroutine analyse_core
  
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

  !> @brief Analyse phase for symmetric matrix.
  !>
  ! TODO Add 32-bits wrapper
  subroutine spldlt_analyse(spldlt_akeep, n, ptr, row, options, inform, order, val, ncpu, ngpu, check)
    use spral_ssids, only: ssids_free
    use spral_metis_wrapper, only : metis_order
    use spral_ssids_akeep, only: ssids_akeep
    use spral_ssids_datatypes
    use spral_ssids_anal, only : expand_pattern, check_order, expand_matrix
    use spral_ssids_inform, only : ssids_inform
    use spral_match_order, only : match_order_metis
    use spral_matrix_util, only : SPRAL_MATRIX_REAL_SYM_INDEF, &
         SPRAL_MATRIX_REAL_SYM_PSDEF, clean_cscl_oop
    use sylver_datatypes_mod, only: sylver_options
#if defined(SPLDLT_USE_STARPU)
    use starpu_f_mod, only: starpu_f_cpu_worker_get_count, starpu_f_cuda_worker_get_count  
#endif
    use sylver_topology_mod, only: sylver_topology_create_flat, sylver_topology_create
    use, intrinsic :: iso_c_binding
    implicit none
    
    type(spldlt_akeep_type), target, intent(inout) :: spldlt_akeep ! spldlt akeep structure 
    integer, intent(in) :: n ! Matrix dimension
    integer(long), intent(in) :: ptr(:)
    integer, intent(in) :: row(:)
    type(sylver_options), target, intent(in) :: options ! SpLDLT options
    type(sylver_inform), intent(inout) :: inform
    integer, dimension(:), allocatable, optional, intent(inout) :: order
    real(wp), optional, intent(in) :: val(:) ! Matrix numerical values
    integer, optional, intent(inout) :: ncpu ! Number of CPU workers
    integer, optional, intent(inout) :: ngpu ! Number of GPU workers
    logical, optional, intent(in) :: check

    character(50)  :: context      ! Procedure name (used when printing).
    logical :: mycheck = .false.
    type(ssids_akeep), pointer :: akeep ! SSIDS akeep structure
    integer :: i
    ! integer, dimension(:), allocatable :: contrib_dest, exec_loc
    integer :: st ! Error management
    integer(long) :: nz     ! entries in expanded matrix
    type(ssids_options) :: ssids_opts ! SSIDS options 
    type(ssids_inform) :: ssids_info ! SSIDS inform

    ! Error flags
    integer :: mu_flag      ! error flag for matrix_util routines
    integer :: mo_flag ! matching-based ordering flag
    integer :: free_flag
    integer :: flag ! Error flag for metis

    integer, dimension(:), allocatable :: order2
    integer(long), dimension(:), allocatable :: ptr2 ! col ptrs for expanded mat
    integer, dimension(:), allocatable :: row2 ! row indices for expanded matrix

    ! The following are only used for matching-based orderings
    real(wp), dimension(:), allocatable :: val_clean ! cleaned values if
      ! val is present and checking is required. 
    real(wp), dimension(:), allocatable :: val2 ! expanded matrix if
      ! val is present.
    
    integer :: ncpu_topo, ngpu_topo
    type(sylver_inform) :: inform_default
    
    st = 0
    ! Prepare analysis phase
    akeep => spldlt_akeep%akeep
    ! Init SSIDS options with SyLVER options
    call set_ssids_options(options, ssids_opts)

    ! Initialize
    context = 'spldlt_analyse'
    inform = inform_default
    ! call ssids_free(akeep, free_flag)
    ! if (free_flag .ne. 0) then
    !    inform%flag = SYLVER_ERROR_CUDA_UNKNOWN
    !    goto 200    
    ! end if
    call spldlt_akeep%free()
    ! Print status on entry
    call options%print_summary_analyse(context)
    if ((options%print_level .ge. 1) .and. (options%unit_diagnostics .ge. 0)) then
       write (options%unit_diagnostics,'(a,i15)') &
            ' n                         =  ',n
    end if

    ! Input checking
    if (present(check)) then
       mycheck = check
    else
       mycheck = .false. ! No checking by default
    end if
       
    akeep%check = mycheck
    akeep%n = n

    ! Checking of matrix data
    if (n .lt. 0) then
       inform%flag = SYLVER_ERROR_A_N_OOR
       goto 200
    end if

    if (n .eq. 0) then
       akeep%nnodes = 0
       allocate(akeep%sptr(0), stat=st) ! used to check if analyse has been run
       if (st .ne. 0) go to 100
       goto 200
    end if

    ! check options%ordering has a valid value
    if ((options%ordering .lt. 0) .or. (options%ordering .gt. 2)) then
       inform%flag = SYLVER_ERROR_ORDER
       goto 200
    end if

    ! check val present when expected
    if (options%ordering .eq. 2) then
       if (.not. present(val)) then
          inform%flag = SYLVER_ERROR_VAL
          goto 200
       end if
    end if

    st = 0
    if (akeep%check) then
       allocate (akeep%ptr(n+1),stat=st)
       if (st .ne. 0) go to 100

       if (present(val)) then
          call clean_cscl_oop(SPRAL_MATRIX_REAL_SYM_INDEF, n, n, ptr, row, &
               akeep%ptr, akeep%row, mu_flag, val_in=val, val_out=val_clean, &
               lmap=akeep%lmap, map=akeep%map, &
               noor=inform%matrix_outrange, ndup=inform%matrix_dup)
       else
          call clean_cscl_oop(SPRAL_MATRIX_REAL_SYM_INDEF, n, n, ptr, row, &
               akeep%ptr, akeep%row, mu_flag, lmap=akeep%lmap, map=akeep%map, &
               noor=inform%matrix_outrange, ndup=inform%matrix_dup)
       end if
       ! Check for errors
       if (mu_flag .lt. 0) then
          if (mu_flag .eq. -1) inform%flag  = SYLVER_ERROR_ALLOCATION
          if (mu_flag .eq. -5) inform%flag  = SYLVER_ERROR_A_PTR
          if (mu_flag .eq. -6) inform%flag  = SYLVER_ERROR_A_PTR
          if (mu_flag .eq. -10) inform%flag = SYLVER_ERROR_A_ALL_OOR
          goto 200
       end if

       ! Check whether warning needs to be raised
       ! Note: same numbering of positive flags as in matrix_util
       if (mu_flag .gt. 0) then
          inform%flag = mu_flag
          call inform%print_flag(options, context)
       end if
       nz = akeep%ptr(n+1) - 1       
       
    else
       nz = ptr(n+1)-1
    end if

    !
    ! If the pivot order is not supplied, we need to compute an order.
    ! Otherwise, we check the supplied order.
    !

    allocate(akeep%invp(n),order2(n),ptr2(n+1),row2(2*nz),stat=st)
    if (st .ne. 0) go to 100
    if (options%ordering .eq. 2) then
       allocate(akeep%scaling(n), val2(2*nz), stat=st)
       if (st .ne. 0) go to 100
    end if

    select case(options%ordering)
    case(0)
       if (.not. present(order)) then
          ! we have an error since user should have supplied the order
          inform%flag = SYLVER_ERROR_ORDER
          goto 200
       end if
       call check_order(n,order,akeep%invp,ssids_opts,ssids_info)
       if (ssids_info%flag .lt. 0) then
          inform%flag = SYLVER_ERROR_ORDER 
          go to 200
       end if
       order2(1:n) = order(1:n)
       if (akeep%check) then
          call expand_pattern(n, nz, akeep%ptr, akeep%row, ptr2, row2)
       else
          call expand_pattern(n, nz, ptr, row, ptr2, row2)
       end if

    case(1)
       ! METIS ordering
       if (akeep%check) then
          call metis_order(n, akeep%ptr, akeep%row, order2, akeep%invp, &
               flag, inform%stat)
          call expand_pattern(n, nz, akeep%ptr, akeep%row, ptr2, row2)
       else
          call metis_order(n, ptr, row, order2, akeep%invp, &
               flag, inform%stat)
          call expand_pattern(n, nz, ptr, row, ptr2, row2)
       end if

       if (flag .lt. 0) then
          inform%flag = SYLVER_ERROR_ORDER
          go to 200
       end if
    case(2)
       ! matching-based ordering required
       ! Expand the matrix as more efficient to do it and then
       ! call match_order_metis() with full matrix supplied

       if (akeep%check) then
          call expand_matrix(n, nz, akeep%ptr, akeep%row, val_clean, ptr2, &
               row2, val2)
          deallocate (val_clean,stat=st)
       else
          call expand_matrix(n, nz, ptr, row, val, ptr2, row2, val2)
       end if

       call match_order_metis(n, ptr2, row2, val2, order2, akeep%scaling, &
            mo_flag, inform%stat)

       select case(mo_flag)
       case(0)
          ! Success; do nothing
       case(1)
          ! singularity warning required
          inform%flag = SYLVER_WARNING_ANAL_SINGULAR
       case(-1)
          inform%flag = SYLVER_ERROR_ALLOCATION
          goto 200
       case default
          inform%flag = SYLVER_ERROR_UNKNOWN
          goto 200
       end select

       deallocate(val2,stat=st)
    end select

    ! Determine the number of CPU workers
    if (present(ncpu)) then
       ! Use the number of CPU workers requested in arguments
       ncpu_topo = ncpu
    else
       ! Use the number of CPU workers enabled when initializing the
       ! runtime system
#if defined(SPLDLT_USE_STARPU)
       !print *, "cpu_worker_get_count = ", starpu_f_cpu_worker_get_count()
       ncpu_topo = starpu_f_cpu_worker_get_count()
#else
       ncpu_topo = 1
#endif
    endif
    
    ! Determine the number of CUDA workers
    if (present(ngpu)) then
       ! Use the number of CUDA workers requested in arguments
       ngpu_topo = ngpu
    else
       ! Use the number of CUDA workers enabled when initializing the
       ! runtime system
#if defined(SPLDLT_USE_STARPU)
       ngpu_topo = starpu_f_cuda_worker_get_count()
#else
       ngpu_topo = 0
#endif
    endif
    
    ! Create machine topology
    !
    ! Allocate and create machine topology in `akeep%topology`
#if defined(SPLDLT_USE_STARPU) && defined(SPLDLT_USE_OMP)
    call sylver_topology_create(ncpu, ngpu, options, akeep%topology)
#else
    call sylver_topology_create_flat(ncpu, ngpu, options, akeep%topology)
#endif

    ! Print machine topology
    if (options%print_level .ge. 1) then
       do i = 1, size(akeep%topology)
          print *, "NUMA region ", i, " with ", akeep%topology(i)%nproc, " cores"
          if(size(akeep%topology(i)%gpus).gt.0) &
               print *, "---> gpus ", akeep%topology(i)%gpus
       end do
    end if
    
    ! perform rest of analyse
    if (akeep%check) then
       call analyse_core(spldlt_akeep, n, akeep%ptr, akeep%row, ptr2, row2, &
            order2, akeep%invp, options, inform)
    else
       call analyse_core(spldlt_akeep, n, ptr, row, ptr2, row2, order2, &
            akeep%invp, options, inform)
    end if

    if (present(order)) order(1:n) = abs(order2(1:n))
    ! if (options%print_level .gt. DEBUG_PRINT_LEVEL) &
    !      print *, "order = ", order2(1:n)

200 continue
    spldlt_akeep%inform = inform
    call inform%print_flag(options, context)
    return
100 continue
    inform%flag = SSIDS_ERROR_ALLOCATION
    inform%stat = st
    goto 200
  end subroutine spldlt_analyse  
  
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  !> @brief Partition an elimination tree for execution on different NUMA regions
  !>        and GPUs.
  !>
  !> Start with a single tree, and proceed top down splitting the largest subtree
  !> (in terms of total flops)  until we have a sufficient number of independent
  !> subtrees. A sufficient number is such that subtrees can be assigned to NUMA
  !> regions and GPUs with a load balance no worse than max_load_inbalance.
  !> Load balance is calculated as the maximum value over all regions/GPUs of:
  !> \f[ \frac{ n x_i / \alpha_i } { \sum_j (x_j/\alpha_j) } \f]
  !> Where \f$ \alpha_i \f$ is the performance coefficient of region/GPU i,
  !> \f$ x_i \f$ is the number of flops assigned to region/GPU i and \f$ n \f$ is
  !> the total number of regions. \f$ \alpha_i \f$ should be proportional to the
  !> speed of the region/GPU (i.e. if GPU is twice as fast as CPU, set alpha for
  !> CPU to 1.0 and alpha for GPU to 2.0).
  !>
  !> If the original number of flops is greater than min_gpu_work and the
  !> performance coefficient of a GPU is greater than the combined coefficients
  !> of the CPU, then subtrees will not be split to become smaller than
  !> min_gpu_work until all GPUs are filled.
  !>
  !> If the balance criterion cannot be satisfied after we have split into
  !> 2 * (total regions/GPUs), we just use the best obtained value.
  !>
  !> GPUs may only handle leaf subtrees, so the top nodes are assigned to the
  !> full set of CPUs.
  !>
  !> Parts are returned as contigous ranges of nodes. Part i consists of nodes
  !> part(i):part(i+1)-1
  !>
  !> @param nnodes Total number of nodes
  !> @param sptr Supernode pointers. Supernode i consists of nodes
  !>        sptr(i):sptr(i+1)-1.
  !> @param sparent Supernode parent array. Supernode i has parent sparent(i).
  !> @param rptr Row pointers. Supernode i has rows rlist(rptr(i):rptr(i+1)-1).
  !> @param topology Machine topology to partition for.
  !> @param min_gpu_work Minimum flops for a GPU execution to be worthwhile.
  !> @param max_load_inbalance Number greater than 1.0 representing maximum
  !>        permissible load inbalance.
  !> @param gpu_perf_coeff The value of \f$ \alpha_i \f$ used for all GPUs,
  !>        assuming that used for all NUMA region CPUs is 1.0.
  !> @param nparts Number of parts found.
  !> @param parts List of part ranges. Part i consists of supernodes
  !>        part(i):part(i+1)-1.
  !> @param exec_loc Execution location. Part i should be run on partition
  !>        mod((exec_loc(i) - 1), size(topology)) + 1.
  !>        It should be run on the CPUs if
  !>        exec_loc(i) <= size(topology),
  !>        otherwise it should be run on GPU number
  !>        (exec_loc(i) - 1)/size(topology).
  !> @param contrib_ptr Contribution pointer. Part i has contribution from
  !>        subtrees contrib_idx(contrib_ptr(i):contrib_ptr(i+1)-1).
  !> @param contrib_idx List of contributing subtrees, see contrib_ptr.
  !> @param contrib_dest Node to which each subtree listed in contrib_idx(:)
  !>        contributes.
  !> @param st Allocation status parameter. If non-zero an allocation error
  !>        occurred.
  subroutine find_subtree_partition(nnodes, sptr, sparent, rptr, options, &
       topology, nparts, part, exec_loc, contrib_ptr, contrib_idx, &
       contrib_dest, inform, st)
    implicit none
    integer, intent(in) :: nnodes
    integer, dimension(nnodes+1), intent(in) :: sptr
    integer, dimension(nnodes), intent(in) :: sparent
    integer(long), dimension(nnodes+1), intent(in) :: rptr
    type(ssids_options), intent(in) :: options
    type(numa_region), dimension(:), intent(in) :: topology
    integer, intent(out) :: nparts
    integer, dimension(:), allocatable, intent(inout) :: part
    integer, dimension(:), allocatable, intent(out) :: exec_loc
    integer, dimension(:), allocatable, intent(inout) :: contrib_ptr
    integer, dimension(:), allocatable, intent(inout) :: contrib_idx
    integer, dimension(:), allocatable, intent(out) :: contrib_dest
    type(sylver_inform), intent(inout) :: inform
    integer, intent(out) :: st

    integer :: i, j, k
    integer(long) :: jj
    integer :: m, n, node
    integer(long), dimension(:), allocatable :: flops
    integer, dimension(:), allocatable :: size_order
    logical, dimension(:), allocatable :: is_child
    real :: load_balance, best_load_balance
    integer :: nregion, ngpu
    logical :: has_parent
    integer(long) :: min_gpu_work
    
    min_gpu_work = options%min_gpu_work
    ! min_gpu_work = 0

    ! Count flops below each node
    allocate(flops(nnodes+1), stat=st)
    if (st .ne. 0) return
    flops(:) = 0
    do node = 1, nnodes
       m = int(rptr(node+1)-rptr(node))
       n = sptr(node+1)-sptr(node)
       do jj = m-n+1, m
          flops(node) = flops(node) + jj**2
       end do
       j = sparent(node)
       flops(j) = flops(j) + flops(node)
       !print *, "Node ", node, "parent", j, " flops ", flops(node)
    end do
    !print *, "Total flops ", flops(nnodes+1)

    ! Initialize partition to be all children of virtual root
    allocate(part(nnodes+1), size_order(nnodes), exec_loc(nnodes), &
         is_child(nnodes), stat=st)
    if (st .ne. 0) return
    nparts = 0
    part(1) = 1
    do i = 1, nnodes
       if (sparent(i) .gt. nnodes) then
          nparts = nparts + 1
          part(nparts+1) = i+1
          is_child(nparts) = .true. ! All subtrees are intially child subtrees
       end if
    end do
    call create_size_order(nparts, part, flops, size_order)
    !print *, "Initial partition has ", nparts, " parts"
    !print *, "part = ", part(1:nparts+1)
    !print *, "size_order = ", size_order(1:nparts)

    ! Calculate number of regions/gpus
    nregion = size(topology)
    ngpu = 0
    do i = 1, size(topology)
       ngpu = ngpu + size(topology(i)%gpus)
    end do
    if(options%print_level .gt. 1) print *, "running on ", nregion, " regions and ", ngpu, " gpus"

    ! Keep splitting until we meet balance criterion
    best_load_balance = huge(best_load_balance)
    do i = 1, 2*(nregion+ngpu)
       ! print *, "size order = ", size_order(1:nparts)
       ! Check load balance criterion
       load_balance = calc_exec_alloc(nparts, part, size_order, is_child,  &
            flops, topology, min_gpu_work, options%gpu_perf_coeff, &
            exec_loc, st)
       if (st .ne. 0) return
       best_load_balance = min(load_balance, best_load_balance)
       if (load_balance .lt. options%max_load_inbalance) exit ! allocation is good
       ! Split tree further
       call split_tree(nparts, part, size_order, is_child, sparent, flops, &
            ngpu, min_gpu_work, st)
       if (st .ne. 0) return
    end do

    if(options%print_level .gt. 1) print *, "[find_subtree_partition] max_load_inbalance = ", options%max_load_inbalance
    if(options%print_level .gt. 1) print *, "[find_subtree_partition] load_balance = ", load_balance

    ! Consolidate adjacent non-children nodes into same part and regen exec_alloc
    !print *
    !print *, "pre merge", part(1:nparts+1)
    ! if(options%print_level .gt. 1) print *, "exec_loc ", exec_loc(1:nparts)
    j = 1
    do i = 2, nparts
       part(j+1) = part(i)
       if (is_child(i) .or. is_child(j)) then
          ! We can't merge j and i
          j = j + 1
          is_child(j) = is_child(i)
       end if
    end do
    part(j+1) = part(nparts+1)
    nparts = j
    !print *, "post merge", part(1:nparts+1)
    call create_size_order(nparts, part, flops, size_order)
    load_balance = calc_exec_alloc(nparts, part, size_order, is_child,  &
         flops, topology, min_gpu_work, options%gpu_perf_coeff, &
         exec_loc, st)
    if (st .ne. 0) return
    !print *, "exec_loc ", exec_loc(1:nparts)
    if(options%print_level .gt. 1) print *, "[find_subtree_partition] load_balance = ", load_balance

    ! Merge adjacent subtrees that are executing on the same node so long as
    ! there is no more than one contribution to a parent subtree
    j = 1
    k = sparent(part(j+1)-1)
    has_parent = (k .le. nnodes)
    do i = 2, nparts
       part(j+1) = part(i)
       exec_loc(j+1) = exec_loc(i)
       k = sparent(part(i+1)-1)
       if ((exec_loc(i) .ne. exec_loc(j)) .or. (has_parent .and. (k .le. nnodes))) then
          ! We can't merge j and i
          j = j + 1
          has_parent = .false. 
       end if
       has_parent = has_parent.or.(k.le.nnodes)
    end do
    part(j+1) = part(nparts+1)
    nparts = j

    ! Figure out contribution blocks that are input to each part
    allocate(contrib_ptr(nparts+3), contrib_idx(nparts), contrib_dest(nparts), &
         stat=st)
    if (st .ne. 0) return
    ! Count contributions at offset +2
    contrib_ptr(3:nparts+3) = 0
    do i = 1, nparts-1 ! by defn, last part has no parent
       j = sparent(part(i+1)-1) ! node index of parent
       if (j .gt. nnodes) cycle ! part is a root
       k = i+1 ! part index of j
       do while(j .ge. part(k+1))
          k = k + 1
       end do
       contrib_ptr(k+2) = contrib_ptr(k+2) + 1
    end do
    ! Figure out contrib_ptr starts at offset +1
    contrib_ptr(1:2) = 1
    do i = 1, nparts
       contrib_ptr(i+2) = contrib_ptr(i+1) + contrib_ptr(i+2)
    end do
    ! print *, "[find_subtree_partition] nparts = ", nparts
    ! print *, "[find_subtree_partition] contrib_dest = ", contrib_dest
    contrib_dest = 0
    ! Drop sources into list    
    do i = 1, nparts-1 ! by defn, last part has no parent
       j = sparent(part(i+1)-1) ! node index of parent
       if (j .gt. nnodes) then
          ! part is a root
          contrib_idx(i) = nparts+1
          cycle
       end if
       k = i+1 ! part index of j
       do while (j .ge. part(k+1))
          k = k + 1
       end do
       contrib_idx(i) = contrib_ptr(k+1)
       ! print *, "[find_subtree_partition] j = ", j
       contrib_dest(contrib_idx(i)) = j
       contrib_ptr(k+1) = contrib_ptr(k+1) + 1
       ! print *, "part = ", i, ", parent = ", j, ", k = ", k, ", contrib_idx = ", contrib_idx(i), &
       !      "contrib_dest = ", contrib_dest(contrib_idx(i))
    end do
    contrib_idx(nparts) = nparts+1 ! last part must be a root
    ! contrib_dest(nparts) = 0
    ! print *, "[find_subtree_partition] contrib_dest = ", contrib_dest

    ! Fill out inform
    inform%nparts = nparts
    inform%gpu_flops = 0
    do i = 1, nparts
       if (exec_loc(i) .gt. size(topology)) &
            inform%gpu_flops = inform%gpu_flops + flops(part(i+1)-1)
    end do
    inform%cpu_flops = flops(nnodes+1) - inform%gpu_flops
  end subroutine find_subtree_partition

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  !> @brief Allocate execution of subtrees to resources and calculate load balance
  !>
  !> Given the partition supplied, uses a greedy algorithm to assign subtrees to
  !> resources specified by topology and then returns the resulting load balance
  !> as
  !> \f[ \frac{\max_i( n x_i / \alpha_i )} { \sum_j (x_j/\alpha_j) } \f]
  !> Where \f$ \alpha_i \f$ is the performance coefficient of region/GPU i,
  !> \f$ x_i \f$ is the number of flops assigned to region/GPU i and \f$ n \f$ is
  !> the total number of regions. \f$ \alpha_i \f$ should be proportional to the
  !> speed of the region/GPU (i.e. if GPU is twice as fast as CPU, set alpha for
  !> CPU to 1.0 and alpha for GPU to 2.0).
  !>
  !> Work is only assigned to GPUs if the subtree has at least min_gpu_work flops.
  !>
  !> None-child subtrees are ignored (they will be executed using all available
  !> resources). They are recorded with exec_loc -1.
  !>
  !> @param nparts Number of parts.
  !> @param parts List of part ranges. Part i consists of supernodes
  !>        part(i):part(i+1)-1.
  !> @param size_order Lists parts in decreasing order of flops.
  !>        i.e. size_order(1) is the largest part.
  !> @param is_child True if subtree is a child subtree (has no contributions
  !>        from other subtrees).
  !> @param flops Number of floating points in subtree rooted at each node.
  !> @param topology Machine topology to allocate execution for.
  !> @param min_gpu_work Minimum work before allocation to GPU is useful.
  !> @param gpu_perf_coeff The value of \f$ \alpha_i \f$ used for all GPUs,
  !>        assuming that used for all NUMA region CPUs is 1.0.
  !> @param exec_loc Execution location. Part i should be run on partition
  !>        mod((exec_loc(i) - 1), size(topology)) + 1.
  !>        It should be run on the CPUs if
  !>        exec_loc(i) <= size(topology),
  !>        otherwise it should be run on GPU number
  !>        (exec_loc(i) - 1)/size(topology).
  !> @param st Allocation status parameter. If non-zero an allocation error
  !>        occurred.
  !> @returns Load balance value as detailed in subroutine description.
  !> @sa find_subtree_partition()
  ! FIXME: Consider case when gpu_perf_coeff > 2.0 ???
  !        (Round robin may not be correct thing)
  real function calc_exec_alloc(nparts, part, size_order, is_child, flops, &
       topology, min_gpu_work, gpu_perf_coeff, exec_loc, st)
    implicit none
    integer, intent(in) :: nparts
    integer, dimension(nparts+1), intent(in) :: part
    integer, dimension(nparts), intent(in) :: size_order
    logical, dimension(nparts), intent(in) :: is_child
    integer(long), dimension(*), intent(in) :: flops
    type(numa_region), dimension(:), intent(in) :: topology
    integer(long), intent(in) :: min_gpu_work
    real, intent(in) :: gpu_perf_coeff
    integer, dimension(nparts), intent(out) :: exec_loc
    integer, intent(out) :: st

    integer :: i, p, nregion, ngpu, max_gpu, next
    integer(long) :: pflops
    integer, dimension(:), allocatable :: map ! List resources in order of
    ! decreasing power
    real, dimension(:), allocatable :: load_balance
    real :: total_balance

    ! Initialise in case of an error return
    calc_exec_alloc = huge(calc_exec_alloc)

    !
    ! Create resource map
    !
    nregion = size(topology)
    ngpu = 0
    max_gpu = 0
    do i = 1, size(topology)
       ngpu = ngpu + size(topology(i)%gpus)
       max_gpu = max(max_gpu, size(topology(i)%gpus))
    end do
    allocate(map(nregion+ngpu), stat=st)
    if (st .ne. 0) return

    if (gpu_perf_coeff .gt. 1.0) then
       ! GPUs are more powerful than CPUs
       next = 1
       do i = 1, size(topology)
          do p = 1, size(topology(i)%gpus)
             map(next) = p*nregion + i
             next = next + 1
          end do
       end do
       do i = 1, size(topology)
          map(next) = i
          next = next + 1
       end do
    else
       ! CPUs are more powerful than GPUs
       next = 1
       do i = 1, size(topology)
          map(next) = i
          next = next + 1
       end do
       do i = 1, size(topology)
          do p = 1, size(topology(i)%gpus)
             map(next) = p*nregion + i
             next = next + 1
          end do
       end do
    end if

    !
    ! Simple round robin allocation in decreasing size order.
    !
    next = 1
    do i = 1, nparts
       p = size_order(i)
       if (.not. is_child(p)) then
          ! Not a child subtree
          exec_loc(p) = -1
          cycle
       end if
       pflops = flops(part(p+1)-1)
       if (pflops .lt. min_gpu_work) then
          ! Avoid GPUs
          do while (map(next) .gt. nregion)
             next = next + 1
             if (next .gt. size(map)) next = 1
          end do
       end if
       exec_loc(p) = map(next)
       next = next + 1
       if (next .gt. size(map)) next = 1
    end do

    !
    ! Calculate load inbalance
    !
    allocate(load_balance(nregion*(1+max_gpu)), stat=st)
    if (st .ne. 0) return
    load_balance(:) = 0.0
    total_balance = 0.0
    ! Sum total 
    do p = 1, nparts
       if (exec_loc(p) .eq. -1) cycle ! not a child subtree
       pflops = flops(part(p+1)-1)
       if (exec_loc(p) .gt. nregion) then
          ! GPU
          load_balance(exec_loc(p)) = load_balance(exec_loc(p)) + &
               real(pflops) / gpu_perf_coeff
          total_balance = total_balance + real(pflops) / gpu_perf_coeff
       else
          ! CPU
          load_balance(exec_loc(p)) = load_balance(exec_loc(p)) + real(pflops)
          total_balance = total_balance + real(pflops)
       end if
    end do
    ! Calculate n * max(x_i/a_i) / sum(x_j/a_j)
    calc_exec_alloc = (nregion+ngpu) * maxval(load_balance(:)) / total_balance
  end function calc_exec_alloc

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!> @brief Split tree into an additional part as required by
!>        find_subtree_partition().
!>
!> Split largest partition into two parts, unless doing so would reduce the
!> number of subtrees with at least min_gpu_work below ngpu.
!>
!> Note: We require all input parts to have a single root.
!>
!> @param nparts Number of parts: normally increased by one on return.
!> @param part Part i consists of nodes part(i):part(i+1).
!> @param size_order Lists parts in decreasing order of flops.
!>        i.e. size_order(1) is the largest part.
!> @param is_child True if subtree is a child subtree (has no contributions
!>        from other subtrees).
!> @param sparent Supernode parent array. Supernode i has parent sparent(i).
!> @param flops Number of floating points in subtree rooted at each node.
!> @param ngpu Number of gpus.
!> @param min_gpu_work Minimum worthwhile work to give to GPU.
!> @param st Allocation status parameter. If non-zero an allocation error
!>        occurred.
!> @sa find_subtree_partition()
  subroutine split_tree(nparts, part, size_order, is_child, sparent, flops, &
       ngpu, min_gpu_work, st)
    implicit none
    integer, intent(inout) :: nparts
    integer, dimension(*), intent(inout) :: part
    integer, dimension(*), intent(inout) :: size_order
    logical, dimension(*), intent(inout) :: is_child
    integer, dimension(*), intent(in) :: sparent
    integer(long), dimension(*), intent(in) :: flops
    integer, intent(in) :: ngpu
    integer(long), intent(in) :: min_gpu_work
    integer, intent(out) :: st

    integer :: i, p, nchild, nbig, root, to_split, old_nparts
    integer, dimension(:), allocatable :: children, temp

    ! Look for all children of root in biggest child part
    nchild = 0
    allocate(children(10), stat=st) ! we will resize if necessary
    if (st.ne.0) return
    ! Find biggest child subtree
    to_split = 1
    do while(.not. is_child(size_order(to_split)))
       to_split = to_split + 1
    end do
    to_split = size_order(to_split)
    ! Find all children of root
    root = part(to_split+1)-1
    do i = part(to_split), root-1
       if (sparent(i) .eq. root) then
          nchild = nchild+1
          if (nchild .gt. size(children)) then
             ! Increase size of children(:)
             allocate(temp(2*size(children)), stat=st)
             if (st .ne. 0) return
             temp(1:size(children)) = children(:)
             deallocate(children)
             call move_alloc(temp, children)
          end if
          children(nchild) = i
       end if
    end do

    ! Check we can split safely
    if (nchild .eq. 0) return ! singleton node, can't split
    nbig = 0 ! number of new parts > min_gpu_work
    do i = to_split+1, nparts
       p = size_order(i)
       if (.not. is_child(p)) cycle ! non-children can't go on GPUs
       root = part(p+1)-1
       if (flops(root) .lt. min_gpu_work) exit
       nbig = nbig + 1
    end do
    if ((nbig+1) .ge. ngpu) then
       ! Original partition met min_gpu_work criterion
       do i = 1, nchild
          if (flops(children(i)) .ge. min_gpu_work) nbig = nbig + 1
       end do
       if (nbig .lt. ngpu) return ! new partition fails min_gpu_work criterion
    end if

    ! Can safely split, so do so. As part to_split was contigous, when
    ! split the new parts fall into the same region. Thus, we first push any
    ! later regions back to make room, then add the new parts.
    part(to_split+nchild+1:nparts+nchild+1) = part(to_split+1:nparts+1)
    is_child(to_split+nchild+1:nparts+nchild) = is_child(to_split+1:nparts)
    do i = 1, nchild
       ! New part corresponding to child i *ends* at part(to_split+i)-1
       part(to_split+i) = children(i)+1
    end do
    is_child(to_split:to_split+nchild-1) = .true.
    is_child(to_split+nchild) = .false. ! Newly created non-parent subtree
    old_nparts = nparts
    nparts = old_nparts + nchild

    ! Finally, recreate size_order array
    call create_size_order(nparts, part, flops, size_order)
  end subroutine split_tree

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!> @brief Determine order of subtrees based on size
!>
!> @note Sorting algorithm could be improved if this becomes a bottleneck.
!>
!> @param nparts Number of parts: normally increased by one on return.
!> @param part Part i consists of nodes part(i):part(i+1).
!> @param flops Number of floating points in subtree rooted at each node.
!> @param size_order Lists parts in decreasing order of flops.
!>        i.e. size_order(1) is the largest part.
  subroutine create_size_order(nparts, part, flops, size_order)
    implicit none
    integer, intent(in) :: nparts
    integer, dimension(nparts+1), intent(in) :: part
    integer(long), dimension(*), intent(in) :: flops
    integer, dimension(nparts), intent(out) :: size_order

    integer :: i, j
    integer(long) :: iflops

    do i = 1, nparts
       ! We assume parts 1:i-1 are in order and aim to insert part i
       iflops = flops(part(i+1)-1)
       do j = 1, i-1
          if (iflops .gt. flops(part(j+1)-1)) exit ! node i belongs in posn j
       end do
       size_order(j+1:i) = size_order(j:i-1)
       size_order(j) = i
    end do
  end subroutine create_size_order

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  ! Tree pruning method. Inspired by the strategy employed in qr_mumps
  ! for pruning the atree.
  subroutine prune_tree(nnodes, sptr, sparent, rptr, nth, ngpu, gpu_perf_coeff, &
       nsubtrees, small, contrib_dest, subtree_sa, subtree_en, exec_loc)
    use spldlt_utils_mod, only: sort
    implicit none

    type node_type
       integer, allocatable :: child(:)
       integer :: least_desc
    end type node_type
    
    integer, intent(in) :: nnodes
    integer, dimension(nnodes+1), intent(in) :: sptr
    integer, dimension(nnodes), intent(in) :: sparent
    integer(long), dimension(nnodes+1), intent(in) :: rptr
    integer, intent(in) :: nth ! Number of CPU workers
    integer, intent(in) :: ngpu ! Number of GPU workers
    real, intent(in) :: gpu_perf_coeff
    integer, intent(out) :: nsubtrees ! Number of partititons: top part plus subtrees
    integer, dimension(:), allocatable, intent(inout) :: small ! Nodes below the lzero layer  
    integer, dimension(:), allocatable, intent(inout) :: contrib_dest ! Node to which each partition contrirbute
    integer, dimension(:), allocatable, intent(inout) :: subtree_sa ! subtree_sa(i) is the first node in subtree i
    integer, dimension(:), allocatable, intent(inout) :: subtree_en ! subtree_sa(i) is the root node in subtree i
    integer, dimension(:), allocatable, intent(inout) :: exec_loc ! Subtree i should be run on NUMA node exec_loc(i)
    
    integer(long), allocatable :: weight(:) ! weight(i) contains weight below node i 
    integer :: j
    integer :: node
    integer :: i
    integer :: c ! child node index
    integer :: nlz ! number of nodes in the lzero layer
    integer :: leaves ! current number of leaf nodes
    integer :: totleaves ! total number of leaf nodes in the atree
    integer :: n ! node to be replaced by its direct descendents in lzero
    integer(long) :: p ! proc 
    integer(long) :: totflops
    real(kind(1.d0)) :: rm ! load balance
    real(kind(1.d0)) :: smallth
    integer, allocatable :: lzero(:)
    integer(long), allocatable :: lzero_w(:), proc_w(:)
    logical :: found
    integer, allocatable :: nchild(:) ! nchild(i) contains the number of child nodes for node i
    type(node_type), allocatable :: nodes(:)
    integer, allocatable :: loc(:) ! locality of node
    integer :: nregion ! Number of workers of regions (NUMA nodes and GPUs)
    real(kind(1.d0)) :: minlb ! Minimum load balance objective
    
    character(50) :: context = 'prune_tree'! Procedure name (used when printing).

    ! Use nth as the number of CPU regions i.e NUMA nodes
    nregion = ngpu + nth 

    ! Count flops below each node
    allocate(weight(nnodes+1))
    weight(:) = 0
    do node = 1, nnodes
       weight(node) = weight(node) + compute_flops(nnodes, sptr, rptr, node)
       j = sparent(node)
       weight(j) = weight(j) + weight(node)
    end do
    
    allocate(lzero_w (nnodes+1))
    allocate(lzero   (nnodes+1))
    allocate(proc_w  (nregion))
    allocate(loc     (nnodes+1))
    
    ! count number of children per node
    allocate(nchild(nnodes+1))
    nchild = 0
    do node = 1, nnodes
       j = sparent(node)
       nchild(j) = nchild(j) + 1
    end do

    ! allocate child nodes list and count leaves
    allocate(nodes(nnodes+1))
    do node = 1, nnodes+1
       allocate(nodes(node)%child(nchild(node)))
       nodes(node)%least_desc = node
    end do

    nchild = 0
    ! list children node
    do node = 1, nnodes
       j = sparent(node) ! get parent node
       nchild(j) = nchild(j) + 1
       nodes(j)%child(nchild(j)) = node ! insert child node in list
       nodes(j)%least_desc = min(nodes(node)%least_desc, nodes(j)%least_desc) ! update least descendent
    end do

    minlb = 0.8
    smallth = 0.01

10  continue
    totleaves = 0
    small = 0
    nsubtrees = 0
    loc = nregion+1 ! Global context by default
    
    totflops = weight(nnodes+1)

    nlz = 0

    node = nnodes+1 ! Root node (symbolic)
    nlz = nlz+1
    lzero(nlz) = node
    lzero_w(nlz) = -weight(node)
    ! count leaf nodes
    do node = 1, nnodes+1
       if(nchild(node) .eq. 0) totleaves = totleaves+1       
    end do
    
    leaves = 0

    godown: do

       ! if (nth .eq. 1) exit ! serial execution process the whole tree as a subtree
       if (nlz .le. 0) exit ! only small nodes ! 
       ! if(nlz .gt. nth*max(2.d0,(log(real(nth,kind(1.d0)))/log(2.d0))**2)) exit ! exit if already too many nodes in l0       

       proc_w = 0
       
       ! sort lzero_w into ascending order and apply the same order on
       ! lzero array
       call sort(lzero_w, nlz, map=lzero)
       ! map subtrees to threads round-robin 
       do i=1, nlz
          ! find the least loaded proc
          p = minloc(proc_w,1)
          if (p .gt. nth) then ! GPU device
             proc_w(p) = proc_w(p) + int((real(abs(lzero_w(i)))/gpu_perf_coeff), kind=long)
          else ! NUMA node
             proc_w(p) = proc_w(p) + abs(lzero_w(i))
          end if
          loc(lzero(i)) = p
       end do

       ! all the subtrees have been mapped. Evaluate load balance
       rm = real(minval(proc_w))/real(maxval(proc_w))

       if(nlz .gt. nregion*max(2.d0,(log(real(nregion,kind(1.d0)))/log(2.d0))**2)) exit ! exit if already too many nodes in l0
       if((rm .gt. minlb) .and. (nlz .ge. 1*nregion)) exit ! if balance is higher than 90%, we're happy

       ! if load is not balanced, replace heaviest node with its kids (if any)
       found = .false.
       findn: do
          if(leaves .eq. totleaves) exit godown ! reached the bottom of the tree

          if(leaves .eq. nlz) then
             if(nlz .ge. nregion*max(2.d0,(log(real(nregion,kind(1.d0)))/log(2.d0))**2)) then 
                exit godown ! all the nodes in l0 are leaves. nothing to do
             else
                smallth = smallth/2.d0
                if(smallth .lt. 1e-4) then
                   exit godown
                else
                   goto 10
                end if
             end if
          end if
          n = lzero(leaves+1) ! n is the node that must be replaced

          ! append children of n
          do i=1, size(nodes(n)%child) ! nchild(n)
             c = nodes(n)%child(i)
             ! print *, "c =", c
             if(real(weight(c), kind(1.d0)) .gt. smallth*real(totflops, kind(1.d0))) then
                ! this child is big enough, add it
                found = .true.
                nlz = nlz+1
                lzero  (nlz) = c
                lzero_w(nlz) = -weight(c)
             else !if (small(c) .eq. 0) then ! make sure this node has not been marked already

                small(nodes(c)%least_desc:c) = -c
                small(c) = 1 ! node is too smal; mark it
                nsubtrees = nsubtrees + 1 ! add new partition
                contrib_dest(nsubtrees) = 0
                if (n .le. nnodes) contrib_dest(nsubtrees) = n
                subtree_sa(nsubtrees) = nodes(c)%least_desc
                subtree_en(nsubtrees) = c
                ! Put it on first proc
                exec_loc(nsubtrees) = 1 ! FIXME small nodes should be re-mapped at the end
                ! exec_loc(nsubtrees) = nth+1 ! Put it in the global context
             end if

          end do
          if(found) exit findn ! if at least one child was added then we redo the mapping
          leaves = leaves+1
       end do findn

       ! swap n with last element
       lzero  (leaves+1) = lzero  (nlz)
       lzero_w(leaves+1) = lzero_w(nlz)
       nlz = nlz-1
    end do godown
              
    do i=1, nlz
       n = lzero(i)
       
       do j=1, size(nodes(n)%child) ! fkeep%nodes(n)%nchild
          c = nodes(n)%child(j)
          if (small(c) .eq. 0) then ! Check if we havn't flaged it already
             small(nodes(c)%least_desc:c) = -c
             small(c) = 1
             nsubtrees = nsubtrees + 1 ! add new partition
             contrib_dest(nsubtrees) = 0
             if (n .le. nnodes) contrib_dest(nsubtrees) = n
             subtree_sa(nsubtrees) = nodes(c)%least_desc
             subtree_en(nsubtrees) = c
             exec_loc(nsubtrees) = loc(n) ! Inherit mapping from parent node 
          end if
       end do
    end do
    
    ! Clean memory
    deallocate(lzero_w)
    deallocate(lzero)
    deallocate(proc_w)
    deallocate(loc)
    
    return
  end subroutine prune_tree

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  !> @brief Print assembly tree in a dot file
  subroutine spldlt_print_atree(nnodes, sptr, sparent, rptr, small, exec_loc)
    use spral_ssids_akeep, only: ssids_akeep
    ! use spral_ssids

    integer, intent(in) :: nnodes
    integer, dimension(nnodes+1), intent(in) :: sptr
    integer, dimension(nnodes), intent(in) :: sparent
    integer(long), dimension(nnodes+1), intent(in) :: rptr
    integer, dimension(:), allocatable, intent(in) :: small ! nodes below the lzero layer  
    integer, dimension(:), allocatable, optional, intent(in) :: exec_loc
    
    integer :: node
    integer :: n, m ! node sizes
    integer :: exec_region ! region of execution for node
    integer(long), dimension(:), allocatable :: flops
    integer :: j
    real :: tot_weight, weight
    ! integer, allocatable :: loc(:) ! locality of node

    ! Count flops below each node
    allocate(flops(nnodes+1))
    flops(:) = 0
    do node = 1, nnodes
       flops(node) = flops(node) + compute_flops(nnodes, sptr, rptr, node)
       j = sparent(node)
       flops(j) = flops(j) + flops(node)
       !print *, "Node ", node, "parent", j, " flops ", flops(node)
    end do
    tot_weight = real(flops(nnodes))
    
    ! print *, "Print atree"

    open(2, file="atree.dot")

    write(2, '("graph atree {")')
    write(2, '("node [")')
    write(2, '("style=filled")')
    write(2, '("]")')

    do node = 1, nnodes

       if (small(node) .lt. 0) cycle
       
       n = sptr(node+1) - sptr(node) 
       m = int(rptr(node+1) - rptr(node))
       weight = real(flops(node)) / tot_weight
       
       ! node id
       write(2, '(i10)', advance="no") node
       write(2, '(" ")', advance="no")
       write(2, '("[")', advance="no")

       ! node info
       write(2, '("label=""")', advance="no")
       write(2, '("node:", i5,"\n")', advance="no")node
       write(2, '("m:", i5,"\n")', advance="no")m
       write(2, '("n:", i5,"\n")', advance="no")n
       write(2, '("w:", f6.2,"\n")', advance="no")100*weight
       ! if (small(node) .eq. 1) then
       !    if (present(exec_loc)) write(2, '("loc:", i4,"\n")', advance="no")exec_loc(node)
       ! end if
       write(2, '("""")', advance="no")
       if (small(node) .eq. 1) then
          write(2, '(" fillcolor=lightgrey")', advance="no")
       else
          write(2, '(" fillcolor=white")', advance="no")
       end if
       write(2, '("]")', advance="no")
       write(2, '(" ")')

       ! parent node
       if(sparent(node) .ne. -1) write(2, '(i10, "--", i10)')sparent(node), node
    end do

    write(2, '("}")')

    close(2)

  end subroutine spldlt_print_atree

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  !> @brief Compute flops for processing a node
  !> @param akeep Information generated in analysis phase by SSIDS  
  !> @param node Node
  function compute_flops(nnodes, sptr, rptr, node)
    implicit none

    integer, intent(in) :: nnodes
    integer, dimension(nnodes+1), intent(in) :: sptr
    integer(long), dimension(nnodes+1), intent(in) :: rptr
    integer, intent(in) :: node ! node index
    integer(long) :: compute_flops ! return value
    
    integer :: n, m ! node sizes
    integer(long) :: jj

    compute_flops = 0
    
    m = int(rptr(node+1)-rptr(node))
    n = sptr(node+1)-sptr(node)
    do jj = m-n+1, m
       compute_flops = compute_flops + jj**2
    end do
    
  end function compute_flops

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  !> @brief Print assembly tree (including partitions) in a dot file
  ! subroutine print_atree_part(nnodes, sptr, sparent, rptr, topology, nparts, & 
  !      part, exec_loc)
  !   implicit none

  !   integer, intent(in) :: nnodes
  !   integer, dimension(nnodes+1), intent(in) :: sptr
  !   integer, dimension(nnodes), intent(in) :: sparent
  !   integer(long), dimension(nnodes+1), intent(in) :: rptr
  !   type(numa_region), dimension(:), intent(in) :: topology
  !   integer, intent(in) :: nparts
  !   integer, dimension(:), allocatable, intent(in) :: part
  !   integer, dimension(:), allocatable, intent(in) :: exec_loc

  !   integer :: node
  !   integer :: n, m ! Node dimensions
  !   integer :: region ! Where to execute node
  !   integer(long), dimension(:), allocatable :: flops
  !   real :: tot_weight, weight
  !   integer :: i, j
  !   character(len=5) :: part_str 
  !   real :: small

  !   ! print *, "[print_atree_part] topology size = ", size(topology)
    
  !   small = 0.001

  !   ! Count flops below each node
  !   allocate(flops(nnodes+1))
  !   flops(:) = 0
  !   do node = 1, nnodes
  !      flops(node) = flops(node) + compute_flops(nnodes, sptr, rptr, node)
  !      j = sparent(node)
  !      if(j .gt. 0) flops(j) = flops(j) + flops(node)
  !      !print *, "Node ", node, "parent", j, " flops ", flops(node)
  !   end do
  !   tot_weight = real(flops(nnodes))

  !   open(2, file="atree_part.dot")

  !   write(2, '("graph atree {")')
  !   write(2, '("node [")')
  !   write(2, '("style=filled")')
  !   write(2, '("]")')

  !   do i = 1, nparts

  !      region = mod((exec_loc(i)-1), size(topology))+1
  !      ! print *, "part = ", i, ", exec_loc = ", exec_loc(i), ", region = ", region 

  !      write(part_str, '(i5)')part(i)
  !      write(2, *)"subgraph cluster"// adjustl(trim(part_str)) // " {"
  !      if ( exec_loc(i) .gt. size(topology)) then ! GPU subtree
  !         write(2, *)"color=red"
  !      else
  !         write(2, *)"color=black"
  !      end if
  !      write(2, '("label=""")', advance="no")
  !      write(2, '("part:", i5,"\n")', advance="no")i
  !      write(2, '("region:", i5,"\n")', advance="no")region
  !      write(2, '("exec_loc:", i5,"\n")', advance="no")exec_loc(i)
  !      write(2, '("""")', advance="no")

  !      do node = part(i), part(i+1)-1

  !         weight = real(flops(node)) / tot_weight 
  !         if (weight .lt. small) cycle ! Prune smallest nodes

  !         n = sptr(node+1) - sptr(node) 
  !         m = int(rptr(node+1) - rptr(node))

  !         ! node idx
  !         write(2, '(i10)', advance="no") node
  !         write(2, '(" ")', advance="no")
  !         write(2, '("[")', advance="no")

  !         ! Node label 
  !         write(2, '("label=""")', advance="no")
  !         write(2, '("node:", i5,"\n")', advance="no")node
  !         write(2, '("m:", i5,"\n")', advance="no")m
  !         write(2, '("n:", i5,"\n")', advance="no")n
  !         write(2, '("w:", f6.2,"\n")', advance="no")100*weight
  !         write(2, '("""")', advance="no")

  !         ! Node color
  !         write(2, '(" fillcolor=white")', advance="no")

  !         write(2, '("]")', advance="no")
  !         write(2, '(" ")')

  !      end do

  !      write(2, '("}")') ! Subgraph

  !      do node = part(i), part(i+1)-1
  !         weight = real(flops(node)) / tot_weight
  !         if (weight .lt. small) cycle ! Prune smallest nodes
  !         if(sparent(node) .ne. -1) write(2, '(i10, "--", i10)')sparent(node), node
  !      end do

  !   end do

  !   write(2, '("}")') ! Graph

  !   close(2)

  ! end subroutine print_atree_part

end module spldlt_analyse_mod
