!> \file
!> \copyright 2016- The Science and Technology Facilities Council (STFC)
!> \author    Jonathan Hogg
!> \author    Florent Lopez
module spldlt_analyse_mod
  use spral_ssids_akeep, only: ssids_akeep 
  use, intrinsic :: iso_c_binding
  use spral_ssids_cpu_iface ! fixme only
  use spral_ssids_datatypes
  use spral_hw_topology, only: numa_region
  use spral_ssids_inform, only : ssids_inform
  implicit none

  !
  ! Data type for information generated in analyse phase
  !
  type spldlt_akeep_type
     type(ssids_akeep) :: akeep ! information generated by SSIDS
     type(c_ptr) :: symbolic_tree_c ! C ptr on symbolic tree
  end type spldlt_akeep_type

  interface spldlt_create_symbolic_tree_c
     ! type(c_ptr) function spldlt_create_symbolic_tree(akeep, n, nnodes, & 
     !      sptr, sparent, rptr, rlist, nptr, nlist, nparts, part, &
     !      contrib_idx, exec_loc, contrib_dest, options) &
     !      bind(C, name="spldlt_create_symbolic_tree")
     !   use, intrinsic :: iso_c_binding
     !   import :: cpu_factor_options
     !   implicit none
     !   type(c_ptr), value :: akeep
     !   integer(c_int), value :: n
     !   integer(c_int), value :: nnodes
     !   integer(c_int), dimension(*), intent(in) :: sptr
     !   integer(c_int), dimension(*), intent(in) :: sparent
     !   integer(c_long), dimension(*), intent(in) :: rptr
     !   integer(c_int), dimension(*), intent(in) :: rlist
     !   integer(c_long), dimension(*), intent(in) :: nptr
     !   integer(c_long), dimension(2, *), intent(in) :: nlist
     !   integer(C_INT), value :: nparts
     !   integer(C_INT), dimension(*), intent(in) :: part
     !   integer(C_INT), dimension(*), intent(in) :: contrib_idx
     !   integer(C_INT), dimension(*), intent(in) :: exec_loc
     !   integer(C_INT), dimension(*), intent(in) :: contrib_dest
     !   type(cpu_factor_options), intent(in) :: options
     ! end function spldlt_create_symbolic_tree

     ! Debug
     type(c_ptr) function spldlt_create_symbolic_tree( &
          akeep, n, nnodes, sptr, sparent, rptr, rlist, nptr, nlist, nparts, &
          part, contrib_idx, exec_loc, contrib_dest) &
          bind(C, name="spldlt_create_symbolic_tree")
       use, intrinsic :: iso_c_binding
       implicit none
       type(c_ptr), value :: akeep
       integer(c_int), value :: n
       integer(c_int), value :: nnodes
       integer(c_int), dimension(*), intent(in) :: sptr
       integer(c_int), dimension(*), intent(in) :: sparent
       integer(c_long), dimension(*), intent(in) :: rptr
       integer(c_int), dimension(*), intent(in) :: rlist
       integer(c_long), dimension(*), intent(in) :: nptr
       integer(c_long), dimension(2, *), intent(in) :: nlist
       integer(c_int), value :: nparts
       integer(c_int), dimension(*), intent(in) :: part
       integer(c_int), dimension(*), intent(in) :: contrib_idx
       integer(c_int), dimension(*), intent(in) :: exec_loc
       integer(c_int), dimension(*), intent(in) :: contrib_dest
     end function spldlt_create_symbolic_tree

  end interface spldlt_create_symbolic_tree_c

contains

  ! Debug
  ! subroutine allocate_cpu_symbolic_subtree()
  !   implicit none
  !   class(cpu_symbolic_subtree), pointer :: this
  ! end subroutine allocate_cpu_symbolic_subtree

  !****************************************************************************
  !
  ! Build a map from A to nodes
  ! lcol( nlist(2,i) ) = val( nlist(1,i) )
  ! nptr defines start of each node in nlist
  !
  ! Note: routine from SSIDS

  subroutine build_map(n, ptr, row, perm, invp, nnodes, sptr, rptr, rlist, &
       nptr, nlist, st)
    implicit none
    ! Original matrix A
    integer, intent(in) :: n
    integer(long), dimension(n+1), intent(in) :: ptr
    integer, dimension(ptr(n+1)-1), intent(in) :: row
    ! Permutation and its inverse (some entries of perm may be negative to
    ! act as flags for 2x2 pivots, so need to use abs(perm))
    integer, dimension(n), intent(in) :: perm
    integer, dimension(n), intent(in) :: invp
    ! Supernode partition of L
    integer, intent(in) :: nnodes
    integer, dimension(nnodes+1), intent(in) :: sptr
    ! Row indices of L
    integer(long), dimension(nnodes+1), intent(in) :: rptr
    integer, dimension(rptr(nnodes+1)-1), intent(in) :: rlist
    ! Output mapping
    integer(long), dimension(nnodes+1), intent(out) :: nptr
    integer(long), dimension(2, ptr(n+1)-1), intent(out) :: nlist
    ! Error check paramter
    integer, intent(out) :: st

    integer :: i, j, k
    integer(long) :: ii, jj, pp
    integer :: blkm
    integer :: col
    integer :: node
    integer, dimension(:), allocatable :: ptr2, row2
    integer(long), dimension(:), allocatable :: origin
    integer, dimension(:), allocatable :: map

    allocate(map(n), ptr2(n+3), row2(ptr(n+1)-1), origin(ptr(n+1)-1), stat=st)
    if (st .ne. 0) return

    !
    ! Build transpose of A in ptr2, row2. Store original posn of entries in
    ! origin array.
    !
    ! Count number of entries in row i in ptr2(i+2). Don't include diagonals.
    ptr2(:) = 0
    do i = 1, n
       do jj = ptr(i), ptr(i+1)-1
          k = row(jj)
          if (k .eq. i) cycle
          ptr2(k+2) = ptr2(k+2) + 1
       end do
    end do
    ! Work out row starts such that row i starts in posn ptr2(i+1)
    ptr2(1:2) = 1
    do i = 1, n
       ptr2(i+2) = ptr2(i+2) + ptr2(i+1)
    end do
    ! Drop entries into place
    do i = 1, n
       do jj = ptr(i), ptr(i+1)-1
          k = row(jj)
          if (k .eq. i) cycle
          row2(ptr2(k+1)) = i
          origin(ptr2(k+1)) = jj
          ptr2(k+1) = ptr2(k+1) + 1
       end do
    end do

    !
    ! Build nptr, nlist map
    !
    pp = 1
    do node = 1, nnodes
       blkm = int(rptr(node+1) - rptr(node))
       nptr(node) = pp

       ! Build map for node indices
       do jj = rptr(node), rptr(node+1)-1
          map(rlist(jj)) = int(jj-rptr(node)+1)
       end do

       ! Build nlist from A-lower transposed
       do j = sptr(node), sptr(node+1)-1
          col = invp(j)
          do i = ptr2(col), ptr2(col+1)-1
             k = abs(perm(row2(i))) ! row of L
             if (k .lt. j) cycle
             nlist(2,pp) = (j-sptr(node))*blkm + map(k)
             nlist(1,pp) = origin(i)
             pp = pp + 1
          end do
       end do

       ! Build nlist from A-lower
       do j = sptr(node), sptr(node+1)-1
          col = invp(j)
          do ii = ptr(col), ptr(col+1)-1
             k = abs(perm(row(ii))) ! row of L
             if (k .lt. j) cycle
             nlist(2,pp) = (j-sptr(node))*blkm + map(k)
             nlist(1,pp) = ii
             pp = pp + 1
          end do
       end do
    end do
    nptr(nnodes+1) = pp
  end subroutine build_map

!****************************************************************************

!
! This routine requires the LOWER and UPPER triangular parts of A
! to be held in CSC format using ptr2 and row2
! AND lower triangular part held using ptr and row.
!
! On exit from this routine, order is set to order
! input to factorization.
!
  subroutine analyse_core(spldlt_akeep, n, ptr, row, ptr2, row2, order, invp, &
       options, inform)
    use spral_core_analyse, only : basic_analyse
    use spral_ssids_cpu_subtree, only : construct_cpu_symbolic_subtree
    implicit none

    type(spldlt_akeep_type), target, intent(inout) :: spldlt_akeep ! spldlt akeep structure 
    integer, intent(in) :: n ! order of system

    type(ssids_options), intent(in) :: options
    type(ssids_inform), intent(inout) :: inform
    integer(long), intent(in) :: ptr(n+1) ! col pointers (lower triangle) 
    integer, intent(in) :: row(ptr(n+1)-1) ! row indices (lower triangle)
    integer(long), intent(in) :: ptr2(n+1) ! col pointers (whole matrix)
    integer, intent(in) :: row2(ptr2(n+1)-1) ! row indices (whole matrix)
    integer, dimension(n), intent(inout) :: order
      !  On exit, holds the pivot order to be used by factorization.
    integer, dimension(n), intent(out) :: invp 
      ! Work array. Used to hold inverse of order but
      ! is NOT set to inverse for the final order that is returned.

    character(50)  :: context ! Procedure name (used when printing).
    type(ssids_akeep), pointer :: akeep ! SSIDS akeep structure

    integer :: nemin, flag
    integer :: i, j
    integer(long) :: nz ! ptr(n+1)-1
    integer, dimension(:), allocatable :: contrib_dest, exec_loc
    integer :: st

    type(c_ptr) :: cakeep

    context = 'ssids_analyse'
    akeep => spldlt_akeep%akeep

    ! Check nemin and set to default if out of range.
    nemin = options%nemin
    if (nemin .lt. 1) nemin = nemin_default

    ! Perform basic analysis so we can figure out subtrees we want to construct
    call basic_analyse(n, ptr2, row2, order, akeep%nnodes, akeep%sptr, &
         akeep%sparent, akeep%rptr,akeep%rlist,                        &
         nemin, flag, inform%stat, inform%num_factor, inform%num_flops)
    select case(flag)
    case(0)
       ! Do nothing
    case(-1)
       ! Allocation error
       inform%flag = SSIDS_ERROR_ALLOCATION
       return
    case(1)
       ! Zero row/column.
       inform%flag = SSIDS_WARNING_ANAL_SINGULAR
    case default
       ! Should never reach here
       inform%flag = SSIDS_ERROR_UNKNOWN
    end select

    ! set invp to hold inverse of order
    do i = 1,n
       invp(order(i)) = i
    end do
    ! any unused variables are at the end and so can set order for them
    do j = akeep%sptr(akeep%nnodes+1), n
       i = invp(j)
       order(i) = 0
    end do

    ! Build map from A to L in nptr, nlist
    nz = ptr(n+1) - 1
    allocate(akeep%nptr(n+1), akeep%nlist(2,nz), stat=st)
    if (st .ne. 0) go to 100
    call build_map(n, ptr, row, order, invp, akeep%nnodes, akeep%sptr, &
         akeep%rptr, akeep%rlist, akeep%nptr, akeep%nlist, st)
    if (st .ne. 0) go to 100

    ! Sort out subtrees
    call find_subtree_partition(akeep%nnodes, akeep%sptr, akeep%sparent,           &
         akeep%rptr, options, akeep%topology, akeep%nparts, akeep%part,            &
         exec_loc, akeep%contrib_ptr, akeep%contrib_idx, contrib_dest, inform, st)
    if (st .ne. 0) go to 100

    print *, " nparts = ", akeep%nparts
    print *, " part = ", akeep%part(1:akeep%nparts+1)
    print *, " exec_loc = ", exec_loc(1:akeep%nparts)
    print *, " contrib_ptr = ", akeep%contrib_ptr(1:akeep%nparts+1)
    print *, " contrib_idx = ", akeep%contrib_idx(1:akeep%nparts)

    ! Construct symbolic subtrees
    allocate(akeep%subtree(akeep%nparts))

    do i = 1, akeep%nparts
       
       akeep%subtree(i)%exec_loc = exec_loc(i)
       ! if (akeep%subtree(i)%exec_loc .eq. -1) cycle
       ! CPU
       akeep%subtree(i)%ptr => construct_cpu_symbolic_subtree(akeep%n,   &
            akeep%part(i), akeep%part(i+1), akeep%sptr, akeep%sparent,   &
            akeep%rptr, akeep%rlist, akeep%nptr, akeep%nlist,            &
            contrib_dest(akeep%contrib_ptr(i):akeep%contrib_ptr(i+1)-1), &
            options)
    end do

    ! call C++ analyse routine
    ! call cpu_copy_options_in(options, coptions)

    cakeep = c_loc(akeep)

    spldlt_akeep%symbolic_tree_c = &
         spldlt_create_symbolic_tree_c(cakeep, akeep%n, akeep%nnodes, & 
         akeep%sptr, akeep%sparent, akeep%rptr, akeep%rlist, akeep%nptr, akeep%nlist, & 
         akeep%nparts, akeep%part, akeep%contrib_idx, exec_loc, contrib_dest)

100 continue
    inform%stat = st
    if (inform%stat .ne. 0) then
       inform%flag = SSIDS_ERROR_ALLOCATION ! TODO Use SPLDLT error codes
    end if
    return
    
  end subroutine analyse_core

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  !> @brief Analyse phase.
  !>
  ! TODO 32-bits wrapper

  subroutine spldlt_analyse(spldlt_akeep, n, ptr, row, options, inform, ncpu, val)
    use spral_ssids, only: ssids_free
    use spral_metis_wrapper, only : metis_order
    use spral_ssids_akeep, only: ssids_akeep
    use spral_ssids_datatypes
    use spral_ssids_anal, only : expand_pattern
    ! use spral_ssids_cpu_subtree, only : construct_cpu_symbolic_subtree, cpu_symbolic_subtree
    use, intrinsic :: iso_c_binding
    implicit none
    
    type(spldlt_akeep_type), target, intent(inout) :: spldlt_akeep ! spldlt akeep structure 
    integer, intent(in) :: n
    integer(long), intent(in) :: ptr(:)
    integer, intent(in) :: row(:)
    type(ssids_options), intent(in) :: options
    type(ssids_inform), intent(inout) :: inform
    integer, intent(inout) :: ncpu ! number of CPU workers
    real(wp), optional, intent(in) :: val(:)

    character(50)  :: context      ! Procedure name (used when printing).
    logical :: check = .false. ! TODO input parameter
    type(ssids_akeep), pointer :: akeep ! ssids akeep structure
    integer nnodes
    type(cpu_factor_options) :: coptions
    integer :: i
    ! integer, dimension(:), allocatable :: contrib_dest, exec_loc
    integer :: st ! Error management
    integer(long) :: nz     ! entries in expanded matrix

    ! Debug
    ! class(cpu_symbolic_subtree), pointer :: subtree_ptr => null()
    ! Error flags
    integer :: free_flag
    integer :: flag         ! error flag for metis

    integer, dimension(:), allocatable :: order2
    integer(long), dimension(:), allocatable :: ptr2 ! col ptrs for expanded mat
    integer, dimension(:), allocatable :: row2 ! row indices for expanded matrix

    ! Prepare analysis phase
    akeep => spldlt_akeep%akeep
    
    ! Initialize
    context = 'spldlt_analyse'
    call ssids_free(akeep, free_flag)
    ! TODO Check error flags for ssids_free
    ! if (free_flag .ne. 0) then
    !    return
    ! end if

    akeep%check = check
    akeep%n = n
    
    ! TODO As in SSIDS analyse_double routine
    ! Checking of matrix data
    ! Check options%ordering has a valid value
    ! check val present when expected

    st = 0
    ! if (check) then
    ! TODO
    ! else
    nz = ptr(n+1)-1
    ! end if

    !
    ! If the pivot order is not supplied, we need to compute an order.
    ! Otherwise, we check the supplied order.
    !

    allocate(akeep%invp(n),order2(n),ptr2(n+1),row2(2*nz),stat=st)

    select case(options%ordering)
    case(0)
       print *, "Not implemented"
       ! TODO
    case(1)
       ! METIS ordering
       call metis_order(n, ptr, row, order2, akeep%invp, &
            flag, inform%stat)
       call expand_pattern(n, nz, ptr, row, ptr2, row2)
    case(2)
       ! matching-based ordering required
       ! Expand the matrix as more efficient to do it and then
       ! call match_order_metis() with full matrix supplied
       print *, "Not implemented"
       ! TODO
    end select


    nnodes = akeep%nnodes
    ! ncpu = 2

    ! print *, "Input topology"
    ! do i = 1, size(akeep%topology)
    !    print *, "Region ", i, " with ", akeep%topology(i)%nproc, " cores"
    !    if(size(akeep%topology(i)%gpus).gt.0) &
    !         print *, "---> gpus ", akeep%topology(i)%gpus
    ! end do

    ! ! Destroy topology given by SSIDS 
    ! if (allocated(akeep%topology)) deallocate(akeep%topology, stat=st)

    ! Figure out topology
    ! Create simple topology with ncpu regions, one for each CPU
    ! worker

    if (allocated(akeep%topology)) deallocate(akeep%topology, stat=st)
    allocate(akeep%topology(ncpu), stat=st)
    do i = 1, ncpu
       akeep%topology(i)%nproc = 1
       allocate(akeep%topology(i)%gpus(0), stat=st)
    end do
    print *, "Input topology"
    do i = 1, size(akeep%topology)
       print *, "Region ", i, " with ", akeep%topology(i)%nproc, " cores"
       if(size(akeep%topology(i)%gpus).gt.0) &
            print *, "---> gpus ", akeep%topology(i)%gpus
    end do

    ! perform rest of analyse
    ! if (check) then
    ! else
    call analyse_core(spldlt_akeep, n, ptr, row, ptr2, row2, order2, akeep%invp, &
         options, inform)
    ! end if

    ! ! Destroy partitions given by SSIDS
    ! if (allocated(akeep%part)) deallocate(akeep%part, stat=st)
    ! if (allocated(akeep%contrib_ptr)) deallocate(akeep%contrib_ptr, stat=st)
    ! if (allocated(akeep%contrib_idx)) deallocate(akeep%contrib_idx, stat=st)

    ! ! Destroy subtrees given by SSIDS 
    ! if (allocated(akeep%subtree)) deallocate(akeep%subtree, stat=st)
    ! if (st .ne. 0) go to 100

    ! Find subtree partition
    ! call find_subtree_partition(akeep%nnodes, akeep%sptr, akeep%sparent,           &
    !      akeep%rptr, options, akeep%topology, akeep%nparts, akeep%part,            &
    !      exec_loc, akeep%contrib_ptr, akeep%contrib_idx, contrib_dest, inform, st)
    ! if (st .ne. 0) go to 100

    ! print *, " nparts = ", akeep%nparts
    ! print *, " part = ", akeep%part
    ! print *, " exec_loc = ", exec_loc
    ! print *, " contrib_idx = ", akeep%contrib_idx
    ! print *, " contrib_ptr = ", akeep%contrib_ptr
    ! print *, " contrib_dest = ", contrib_dest

    ! akeep%nparts = 10
    ! allocate(akeep%part(akeep%nnodes+1), exec_loc(akeep%nnodes))
    ! akeep%part = (/1,  2,  7,  8,  9, 12, 13, 18, 19, 20, 25, 12, 13, 14, &
    !      15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25/)
    ! allocate(akeep%contrib_ptr(akeep%nparts+3), akeep%contrib_idx(akeep%nparts), &  
    !      contrib_dest(akeep%nparts))
    ! exec_loc = (/2, -1,  1,  2, -1,  1, -1,  2,  1, -1, -1,  1, -1, -1, & 
    !      -1, -1, -1,  2,  1, -1, -1, -1, -1, -1 /)
    ! akeep%contrib_idx = (/1,  5,  2,  3,  6,  4,  7,  8,  9, 11/)
    ! akeep%contrib_ptr = (/1,  1,  2,  2,  2,  4,  4, 5, 5, 5, 10, 10, 0/)
    ! contrib_dest = (/2,  9,  9, 13, 24, 24, 23, 20, 20,  0/)

    ! do i = 1, akeep%nparts
    !    ! print *, "part ", i, ", sa = ", akeep%part(i), ", en = ", akeep%part(i+1)-1, &
    !    !      ", contrib_idx = ", akeep%contrib_idx(akeep%contrib_ptr(i):akeep%contrib_ptr(i+1)-1)
    !    ! print *, "part ", i, "exec_loc = ", exec_loc(i), ", sa = ", akeep%part(i), ", en = ", akeep%part(i+1)-1, &
    !    !      ", contrib_idx = ", akeep%contrib_idx(akeep%contrib_ptr(i):akeep%contrib_ptr(i+1)-1), &
    !    !      ", contrib_dest = ", contrib_dest(akeep%contrib_ptr(i):akeep%contrib_ptr(i+1)-1)

    !    print *, "part ", i, ", sa = ", akeep%part(i), ", en = ", akeep%part(i+1)-1, &
    !         ", contrib_idx = ", akeep%contrib_idx(i), &
    !         ", exec_loc = ", exec_loc(i)
    !         ! ", contrib_ptr(i) = ", akeep%contrib_ptr(i), ", contrib_ptr(i+1)-1 = ", akeep%contrib_ptr(i+1)-1 
    !         ! ", contrib_dest = ", contrib_dest(akeep%contrib_ptr(i):akeep%contrib_ptr(i+1)-1)

    ! end do
    
    ! ! Setup subtrees
    ! allocate(akeep%subtree(akeep%nparts), stat=st)
    ! if (st .ne. 0) go to 100

    ! do i = 1, akeep%nparts
    !    ! Set execution location for i-th subtree
    !    akeep%subtree(i)%exec_loc = exec_loc(i)
    !    ! CPU
    !    !print *, numa_region, "init cpu subtree ", i, akeep%part(i), &
    !    !   akeep%part(i+1)-1
    !    ! allocate(akeep%subtree(i)%ptr)

    !    ! akeep%subtree(i)%ptr => construct_cpu_symbolic_subtree(akeep%n,   &
    !    !      akeep%part(i), akeep%part(i+1), akeep%sptr, akeep%sparent,   &
    !    !      akeep%rptr, akeep%rlist, akeep%nptr, akeep%nlist,            &
    !    !      contrib_dest(akeep%contrib_ptr(i):akeep%contrib_ptr(i+1)-1), &
    !    !      options)

    !    ! debug
    !    allocate(subtree_ptr)
    !    akeep%subtree(i)%ptr => subtree_ptr
    !    nullify(subtree_ptr) 

    ! end do
    ! print *, "[spldlt_analyse] nnodes: ", nnodes
    ! print *, "sptr: ", akeep%sptr(1:nnodes+1)

    ! call C++ analyse routine
    ! call cpu_copy_options_in(options, coptions)
    ! debug
    ! spldlt_akeep%symbolic_tree_c = &
    !      spldlt_create_symbolic_tree_c(c_loc(akeep), akeep%n, nnodes, akeep%sptr, &
    !      akeep%sparent, akeep%rptr, akeep%rlist, akeep%nptr, akeep%nlist, &
    !      akeep%nparts, akeep%part, akeep%contrib_idx, exec_loc, contrib_dest, & 
    !      coptions)

    return
100 continue
        
    print *, "[Error][spldlt_analyse] st: ", st

    return
  end subroutine spldlt_analyse
  
  !****************************************************************************
  
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  !> @brief Partition an elimination tree for execution on different NUMA regions
  !>        and GPUs.
  !>
  !> Start with a single tree, and proceed top down splitting the largest subtree
  !> (in terms of total flops)  until we have a sufficient number of independent
  !> subtrees. A sufficient number is such that subtrees can be assigned to NUMA
  !> regions and GPUs with a load balance no worse than max_load_inbalance.
  !> Load balance is calculated as the maximum value over all regions/GPUs of:
  !> \f[ \frac{ n x_i / \alpha_i } { \sum_j (x_j/\alpha_j) } \f]
  !> Where \f$ \alpha_i \f$ is the performance coefficient of region/GPU i,
  !> \f$ x_i \f$ is the number of flops assigned to region/GPU i and \f$ n \f$ is
  !> the total number of regions. \f$ \alpha_i \f$ should be proportional to the
  !> speed of the region/GPU (i.e. if GPU is twice as fast as CPU, set alpha for
  !> CPU to 1.0 and alpha for GPU to 2.0).
  !>
  !> If the original number of flops is greater than min_gpu_work and the
  !> performance coefficient of a GPU is greater than the combined coefficients
  !> of the CPU, then subtrees will not be split to become smaller than
  !> min_gpu_work until all GPUs are filled.
  !>
  !> If the balance criterion cannot be satisfied after we have split into
  !> 2 * (total regions/GPUs), we just use the best obtained value.
  !>
  !> GPUs may only handle leaf subtrees, so the top nodes are assigned to the
  !> full set of CPUs.
  !>
  !> Parts are returned as contigous ranges of nodes. Part i consists of nodes
  !> part(i):part(i+1)-1
  !>
  !> @param nnodes Total number of nodes
  !> @param sptr Supernode pointers. Supernode i consists of nodes
  !>        sptr(i):sptr(i+1)-1.
  !> @param sparent Supernode parent array. Supernode i has parent sparent(i).
  !> @param rptr Row pointers. Supernode i has rows rlist(rptr(i):rptr(i+1)-1).
  !> @param topology Machine topology to partition for.
  !> @param min_gpu_work Minimum flops for a GPU execution to be worthwhile.
  !> @param max_load_inbalance Number greater than 1.0 representing maximum
  !>        permissible load inbalance.
  !> @param gpu_perf_coeff The value of \f$ \alpha_i \f$ used for all GPUs,
  !>        assuming that used for all NUMA region CPUs is 1.0.
  !> @param nparts Number of parts found.
  !> @param parts List of part ranges. Part i consists of supernodes
  !>        part(i):part(i+1)-1.
  !> @param exec_loc Execution location. Part i should be run on partition
  !>        mod((exec_loc(i) - 1), size(topology)) + 1.
  !>        It should be run on the CPUs if
  !>        exec_loc(i) <= size(topology),
  !>        otherwise it should be run on GPU number
  !>        (exec_loc(i) - 1)/size(topology).
  !> @param contrib_ptr Contribution pointer. Part i has contribution from
  !>        subtrees contrib_idx(contrib_ptr(i):contrib_ptr(i+1)-1).
  !> @param contrib_idx List of contributing subtrees, see contrib_ptr.
  !> @param contrib_dest Node to which each subtree listed in contrib_idx(:)
  !>        contributes.
  !> @param st Allocation status parameter. If non-zero an allocation error
  !>        occurred.
  subroutine find_subtree_partition(nnodes, sptr, sparent, rptr, options, &
       topology, nparts, part, exec_loc, contrib_ptr, contrib_idx, &
       contrib_dest, inform, st)
    implicit none
    integer, intent(in) :: nnodes
    integer, dimension(nnodes+1), intent(in) :: sptr
    integer, dimension(nnodes), intent(in) :: sparent
    integer(long), dimension(nnodes+1), intent(in) :: rptr
    type(ssids_options), intent(in) :: options
    type(numa_region), dimension(:), intent(in) :: topology
    integer, intent(out) :: nparts
    integer, dimension(:), allocatable, intent(inout) :: part
    integer, dimension(:), allocatable, intent(out) :: exec_loc
    integer, dimension(:), allocatable, intent(inout) :: contrib_ptr
    integer, dimension(:), allocatable, intent(inout) :: contrib_idx
    integer, dimension(:), allocatable, intent(out) :: contrib_dest
    type(ssids_inform), intent(inout) :: inform
    integer, intent(out) :: st

    integer :: i, j, k
    integer(long) :: jj
    integer :: m, n, node
    integer(long), dimension(:), allocatable :: flops
    integer, dimension(:), allocatable :: size_order
    logical, dimension(:), allocatable :: is_child
    real :: load_balance, best_load_balance
    integer :: nregion, ngpu
    logical :: has_parent

    ! Count flops below each node
    allocate(flops(nnodes+1), stat=st)
    if (st .ne. 0) return
    flops(:) = 0
    do node = 1, nnodes
       m = int(rptr(node+1)-rptr(node))
       n = sptr(node+1)-sptr(node)
       do jj = m-n+1, m
          flops(node) = flops(node) + jj**2
       end do
       j = sparent(node)
       flops(j) = flops(j) + flops(node)
       !print *, "Node ", node, "parent", j, " flops ", flops(node)
    end do
    !print *, "Total flops ", flops(nnodes+1)

    ! Initialize partition to be all children of virtual root
    allocate(part(nnodes+1), size_order(nnodes), exec_loc(nnodes), &
         is_child(nnodes), stat=st)
    if (st .ne. 0) return
    nparts = 0
    part(1) = 1
    do i = 1, nnodes
       if (sparent(i) .gt. nnodes) then
          nparts = nparts + 1
          part(nparts+1) = i+1
          is_child(nparts) = .true. ! All subtrees are intially child subtrees
       end if
    end do
    call create_size_order(nparts, part, flops, size_order)
    !print *, "Initial partition has ", nparts, " parts"
    !print *, "part = ", part(1:nparts+1)
    !print *, "size_order = ", size_order(1:nparts)

    ! Calculate number of regions/gpus
    nregion = size(topology)
    ngpu = 0
    do i = 1, size(topology)
       ngpu = ngpu + size(topology(i)%gpus)
    end do
    print *, "running on ", nregion, " regions and ", ngpu, " gpus"

    ! Keep splitting until we meet balance criterion
    best_load_balance = huge(best_load_balance)
    do i = 1, 2*(nregion+ngpu)
       ! Check load balance criterion
       load_balance = calc_exec_alloc(nparts, part, size_order, is_child,  &
            flops, topology, options%min_gpu_work, options%gpu_perf_coeff, &
            exec_loc, st)
       if (st .ne. 0) return
       best_load_balance = min(load_balance, best_load_balance)
       if (load_balance .lt. options%max_load_inbalance) exit ! allocation is good
       ! Split tree further
       call split_tree(nparts, part, size_order, is_child, sparent, flops, &
            ngpu, options%min_gpu_work, st)
       if (st .ne. 0) return
    end do

    print *, "[find_subtree_partition] max_load_inbalance = ", options%max_load_inbalance
    print *, "[find_subtree_partition] load_balance = ", load_balance

    ! Consolidate adjacent non-children nodes into same part and regen exec_alloc
    !print *
    !print *, "pre merge", part(1:nparts+1)
    !print *, "exec_loc ", exec_loc(1:nparts)
    j = 1
    do i = 2, nparts
       part(j+1) = part(i)
       if (is_child(i) .or. is_child(j)) then
          ! We can't merge j and i
          j = j + 1
          is_child(j) = is_child(i)
       end if
    end do
    part(j+1) = part(nparts+1)
    nparts = j
    !print *, "post merge", part(1:nparts+1)
    call create_size_order(nparts, part, flops, size_order)
    load_balance = calc_exec_alloc(nparts, part, size_order, is_child,  &
         flops, topology, options%min_gpu_work, options%gpu_perf_coeff, &
         exec_loc, st)
    if (st .ne. 0) return
    !print *, "exec_loc ", exec_loc(1:nparts)
    print *, "[find_subtree_partition] load_balance = ", load_balance

    ! Merge adjacent subtrees that are executing on the same node so long as
    ! there is no more than one contribution to a parent subtree
    j = 1
    k = sparent(part(j+1)-1)
    has_parent = (k .le. nnodes)
    do i = 2, nparts
       part(j+1) = part(i)
       exec_loc(j+1) = exec_loc(i)
       k = sparent(part(i+1)-1)
       if ((exec_loc(i) .ne. exec_loc(j)) .or. (has_parent .and. (k .le. nnodes))) then
          ! We can't merge j and i
          j = j + 1
          has_parent = .false. 
       end if
       has_parent = has_parent.or.(k.le.nnodes)
    end do
    part(j+1) = part(nparts+1)
    nparts = j

    ! Figure out contribution blocks that are input to each part
    allocate(contrib_ptr(nparts+3), contrib_idx(nparts), contrib_dest(nparts), &
         stat=st)
    if (st .ne. 0) return
    ! Count contributions at offset +2
    contrib_ptr(3:nparts+3) = 0
    do i = 1, nparts-1 ! by defn, last part has no parent
       j = sparent(part(i+1)-1) ! node index of parent
       if (j .gt. nnodes) cycle ! part is a root
       k = i+1 ! part index of j
       do while(j .ge. part(k+1))
          k = k + 1
       end do
       contrib_ptr(k+2) = contrib_ptr(k+2) + 1
    end do
    ! Figure out contrib_ptr starts at offset +1
    contrib_ptr(1:2) = 1
    do i = 1, nparts
       contrib_ptr(i+2) = contrib_ptr(i+1) + contrib_ptr(i+2)
    end do
    ! print *, "[find_subtree_partition] nparts = ", nparts
    ! print *, "[find_subtree_partition] contrib_dest = ", contrib_dest
    contrib_dest = 0
    ! Drop sources into list    
    do i = 1, nparts-1 ! by defn, last part has no parent
       j = sparent(part(i+1)-1) ! node index of parent
       if (j .gt. nnodes) then
          ! part is a root
          contrib_idx(i) = nparts+1
          cycle
       end if
       k = i+1 ! part index of j
       do while (j .ge. part(k+1))
          k = k + 1
       end do
       contrib_idx(i) = contrib_ptr(k+1)
       ! print *, "[find_subtree_partition] j = ", j
       contrib_dest(contrib_idx(i)) = j
       contrib_ptr(k+1) = contrib_ptr(k+1) + 1
       ! print *, "part = ", i, ", parent = ", j, ", k = ", k, ", contrib_idx = ", contrib_idx(i), &
       !      "contrib_dest = ", contrib_dest(contrib_idx(i))
    end do
    contrib_idx(nparts) = nparts+1 ! last part must be a root
    ! contrib_dest(nparts) = 0
    ! print *, "[find_subtree_partition] contrib_dest = ", contrib_dest

    ! Fill out inform
    inform%nparts = nparts
    inform%gpu_flops = 0
    do i = 1, nparts
       if (exec_loc(i) .gt. size(topology)) &
            inform%gpu_flops = inform%gpu_flops + flops(part(i+1)-1)
    end do
    inform%cpu_flops = flops(nnodes+1) - inform%gpu_flops
  end subroutine find_subtree_partition

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  !> @brief Allocate execution of subtrees to resources and calculate load balance
  !>
  !> Given the partition supplied, uses a greedy algorithm to assign subtrees to
  !> resources specified by topology and then returns the resulting load balance
  !> as
  !> \f[ \frac{\max_i( n x_i / \alpha_i )} { \sum_j (x_j/\alpha_j) } \f]
  !> Where \f$ \alpha_i \f$ is the performance coefficient of region/GPU i,
  !> \f$ x_i \f$ is the number of flops assigned to region/GPU i and \f$ n \f$ is
  !> the total number of regions. \f$ \alpha_i \f$ should be proportional to the
  !> speed of the region/GPU (i.e. if GPU is twice as fast as CPU, set alpha for
  !> CPU to 1.0 and alpha for GPU to 2.0).
  !>
  !> Work is only assigned to GPUs if the subtree has at least min_gpu_work flops.
  !>
  !> None-child subtrees are ignored (they will be executed using all available
  !> resources). They are recorded with exec_loc -1.
  !>
  !> @param nparts Number of parts.
  !> @param parts List of part ranges. Part i consists of supernodes
  !>        part(i):part(i+1)-1.
  !> @param size_order Lists parts in decreasing order of flops.
  !>        i.e. size_order(1) is the largest part.
  !> @param is_child True if subtree is a child subtree (has no contributions
  !>        from other subtrees).
  !> @param flops Number of floating points in subtree rooted at each node.
  !> @param topology Machine topology to allocate execution for.
  !> @param min_gpu_work Minimum work before allocation to GPU is useful.
  !> @param gpu_perf_coeff The value of \f$ \alpha_i \f$ used for all GPUs,
  !>        assuming that used for all NUMA region CPUs is 1.0.
  !> @param exec_loc Execution location. Part i should be run on partition
  !>        mod((exec_loc(i) - 1), size(topology)) + 1.
  !>        It should be run on the CPUs if
  !>        exec_loc(i) <= size(topology),
  !>        otherwise it should be run on GPU number
  !>        (exec_loc(i) - 1)/size(topology).
  !> @param st Allocation status parameter. If non-zero an allocation error
  !>        occurred.
  !> @returns Load balance value as detailed in subroutine description.
  !> @sa find_subtree_partition()
  ! FIXME: Consider case when gpu_perf_coeff > 2.0 ???
  !        (Round robin may not be correct thing)
  real function calc_exec_alloc(nparts, part, size_order, is_child, flops, &
       topology, min_gpu_work, gpu_perf_coeff, exec_loc, st)
    implicit none
    integer, intent(in) :: nparts
    integer, dimension(nparts+1), intent(in) :: part
    integer, dimension(nparts), intent(in) :: size_order
    logical, dimension(nparts), intent(in) :: is_child
    integer(long), dimension(*), intent(in) :: flops
    type(numa_region), dimension(:), intent(in) :: topology
    integer(long), intent(in) :: min_gpu_work
    real, intent(in) :: gpu_perf_coeff
    integer, dimension(nparts), intent(out) :: exec_loc
    integer, intent(out) :: st

    integer :: i, p, nregion, ngpu, max_gpu, next
    integer(long) :: pflops
    integer, dimension(:), allocatable :: map ! List resources in order of
    ! decreasing power
    real, dimension(:), allocatable :: load_balance
    real :: total_balance

    ! Initialise in case of an error return
    calc_exec_alloc = huge(calc_exec_alloc)

    !
    ! Create resource map
    !
    nregion = size(topology)
    ngpu = 0
    max_gpu = 0
    do i = 1, size(topology)
       ngpu = ngpu + size(topology(i)%gpus)
       max_gpu = max(max_gpu, size(topology(i)%gpus))
    end do
    allocate(map(nregion+ngpu), stat=st)
    if (st .ne. 0) return

    if (gpu_perf_coeff .gt. 1.0) then
       ! GPUs are more powerful than CPUs
       next = 1
       do i = 1, size(topology)
          do p = 1, size(topology(i)%gpus)
             map(next) = p*nregion + i
             next = next + 1
          end do
       end do
       do i = 1, size(topology)
          map(next) = i
          next = next + 1
       end do
    else
       ! CPUs are more powerful than GPUs
       next = 1
       do i = 1, size(topology)
          map(next) = i
          next = next + 1
       end do
       do i = 1, size(topology)
          do p = 1, size(topology(i)%gpus)
             map(next) = p*nregion + i
             next = next + 1
          end do
       end do
    end if

    !
    ! Simple round robin allocation in decreasing size order.
    !
    next = 1
    do i = 1, nparts
       p = size_order(i)
       if (.not. is_child(p)) then
          ! Not a child subtree
          exec_loc(p) = -1
          cycle
       end if
       pflops = flops(part(p+1)-1)
       if (pflops .lt. min_gpu_work) then
          ! Avoid GPUs
          do while (map(next) .gt. nregion)
             next = next + 1
             if (next .gt. size(map)) next = 1
          end do
       end if
       exec_loc(p) = map(next)
       next = next + 1
       if (next .gt. size(map)) next = 1
    end do

    !
    ! Calculate load inbalance
    !
    allocate(load_balance(nregion*(1+max_gpu)), stat=st)
    if (st .ne. 0) return
    load_balance(:) = 0.0
    total_balance = 0.0
    ! Sum total 
    do p = 1, nparts
       if (exec_loc(p) .eq. -1) cycle ! not a child subtree
       pflops = flops(part(p+1)-1)
       if (exec_loc(p) .gt. nregion) then
          ! GPU
          load_balance(exec_loc(p)) = load_balance(exec_loc(p)) + &
               real(pflops) / gpu_perf_coeff
          total_balance = total_balance + real(pflops) / gpu_perf_coeff
       else
          ! CPU
          load_balance(exec_loc(p)) = load_balance(exec_loc(p)) + real(pflops)
          total_balance = total_balance + real(pflops)
       end if
    end do
    ! Calculate n * max(x_i/a_i) / sum(x_j/a_j)
    calc_exec_alloc = (nregion+ngpu) * maxval(load_balance(:)) / total_balance
  end function calc_exec_alloc

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!> @brief Split tree into an additional part as required by
!>        find_subtree_partition().
!>
!> Split largest partition into two parts, unless doing so would reduce the
!> number of subtrees with at least min_gpu_work below ngpu.
!>
!> Note: We require all input parts to have a single root.
!>
!> @param nparts Number of parts: normally increased by one on return.
!> @param part Part i consists of nodes part(i):part(i+1).
!> @param size_order Lists parts in decreasing order of flops.
!>        i.e. size_order(1) is the largest part.
!> @param is_child True if subtree is a child subtree (has no contributions
!>        from other subtrees).
!> @param sparent Supernode parent array. Supernode i has parent sparent(i).
!> @param flops Number of floating points in subtree rooted at each node.
!> @param ngpu Number of gpus.
!> @param min_gpu_work Minimum worthwhile work to give to GPU.
!> @param st Allocation status parameter. If non-zero an allocation error
!>        occurred.
!> @sa find_subtree_partition()
  subroutine split_tree(nparts, part, size_order, is_child, sparent, flops, &
       ngpu, min_gpu_work, st)
    implicit none
    integer, intent(inout) :: nparts
    integer, dimension(*), intent(inout) :: part
    integer, dimension(*), intent(inout) :: size_order
    logical, dimension(*), intent(inout) :: is_child
    integer, dimension(*), intent(in) :: sparent
    integer(long), dimension(*), intent(in) :: flops
    integer, intent(in) :: ngpu
    integer(long), intent(in) :: min_gpu_work
    integer, intent(out) :: st

    integer :: i, p, nchild, nbig, root, to_split, old_nparts
    integer, dimension(:), allocatable :: children, temp

    ! Look for all children of root in biggest child part
    nchild = 0
    allocate(children(10), stat=st) ! we will resize if necessary
    if (st.ne.0) return
    ! Find biggest child subtree
    to_split = 1
    do while(.not. is_child(size_order(to_split)))
       to_split = to_split + 1
    end do
    to_split = size_order(to_split)
    ! Find all children of root
    root = part(to_split+1)-1
    do i = part(to_split), root-1
       if (sparent(i) .eq. root) then
          nchild = nchild+1
          if (nchild .gt. size(children)) then
             ! Increase size of children(:)
             allocate(temp(2*size(children)), stat=st)
             if (st .ne. 0) return
             temp(1:size(children)) = children(:)
             deallocate(children)
             call move_alloc(temp, children)
          end if
          children(nchild) = i
       end if
    end do

    ! Check we can split safely
    if (nchild .eq. 0) return ! singleton node, can't split
    nbig = 0 ! number of new parts > min_gpu_work
    do i = to_split+1, nparts
       p = size_order(i)
       if (.not. is_child(p)) cycle ! non-children can't go on GPUs
       root = part(p+1)-1
       if (flops(root) .lt. min_gpu_work) exit
       nbig = nbig + 1
    end do
    if ((nbig+1) .ge. ngpu) then
       ! Original partition met min_gpu_work criterion
       do i = 1, nchild
          if (flops(children(i)) .ge. min_gpu_work) nbig = nbig + 1
       end do
       if (nbig .lt. ngpu) return ! new partition fails min_gpu_work criterion
    end if

    ! Can safely split, so do so. As part to_split was contigous, when
    ! split the new parts fall into the same region. Thus, we first push any
    ! later regions back to make room, then add the new parts.
    part(to_split+nchild+1:nparts+nchild+1) = part(to_split+1:nparts+1)
    is_child(to_split+nchild+1:nparts+nchild) = is_child(to_split+1:nparts)
    do i = 1, nchild
       ! New part corresponding to child i *ends* at part(to_split+i)-1
       part(to_split+i) = children(i)+1
    end do
    is_child(to_split:to_split+nchild-1) = .true.
    is_child(to_split+nchild) = .false. ! Newly created non-parent subtree
    old_nparts = nparts
    nparts = old_nparts + nchild

    ! Finally, recreate size_order array
    call create_size_order(nparts, part, flops, size_order)
  end subroutine split_tree

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!> @brief Determine order of subtrees based on size
!>
!> @note Sorting algorithm could be improved if this becomes a bottleneck.
!>
!> @param nparts Number of parts: normally increased by one on return.
!> @param part Part i consists of nodes part(i):part(i+1).
!> @param flops Number of floating points in subtree rooted at each node.
!> @param size_order Lists parts in decreasing order of flops.
!>        i.e. size_order(1) is the largest part.
  subroutine create_size_order(nparts, part, flops, size_order)
    implicit none
    integer, intent(in) :: nparts
    integer, dimension(nparts+1), intent(in) :: part
    integer(long), dimension(*), intent(in) :: flops
    integer, dimension(nparts), intent(out) :: size_order

    integer :: i, j
    integer(long) :: iflops

    do i = 1, nparts
       ! We assume parts 1:i-1 are in order and aim to insert part i
       iflops = flops(part(i+1)-1)
       do j = 1, i-1
          if (iflops .gt. flops(part(j+1)-1)) exit ! node i belongs in posn j
       end do
       size_order(j+1:i) = size_order(j:i-1)
       size_order(j) = i
    end do
  end subroutine create_size_order
  
  subroutine spldlt_print_atree(akeep)
    use spral_ssids_akeep, only: ssids_akeep
    ! use spral_ssids

    type(ssids_akeep), intent(in) :: akeep

    integer :: num_nodes
    integer :: node
    integer :: n, m ! node sizes
    integer :: exec_region ! region of execution for node

    print *, "Print atree"

    num_nodes = akeep%nnodes

    print *, "num_nodes: ", num_nodes

    open(2, file="atree.dot")

    write(2, '("graph atree {")')
    write(2, '("node [")')
    write(2, '("style=filled")')
    write(2, '("]")')

    do node = 1, num_nodes

       n = akeep%sptr(node+1) - akeep%sptr(node) 
       m = int(akeep%rptr(node+1) - akeep%rptr(node))

       ! node id
       write(2, '(i10)', advance="no") node
       write(2, '(" ")', advance="no")
       write(2, '("[")', advance="no")

       ! node info
       write(2, '("label=""")', advance="no")
       write(2, '("node:", i5,"\n")', advance="no")node
       write(2, '("m:", i5,"\n")', advance="no")m
       write(2, '("n:", i5,"\n")', advance="no")n

       write(2, '("""")', advance="no")
       write(2, '("]")', advance="no")
       write(2, '(" ")')

       ! parent node
       if(akeep%sparent(node) .ne. -1) write(2, '(i10, "--", i10)')akeep%sparent(node), node
    end do

    write(2, '("}")')

    close(2)

  end subroutine spldlt_print_atree

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  !> @brief Compute flops for processing a node
  !> @param akeep Information generated in analysis phase by SSIDS  
  !> @param node Node
  function compute_flops(akeep, node)
    use spral_ssids_akeep, only: ssids_akeep
    implicit none

    type(ssids_akeep), intent(in) :: akeep
    integer, intent(in) :: node
    integer(long) :: compute_flops
    
    integer :: n, m ! node sizes
    integer(long) :: jj    

    compute_flops = 0 
    
    m = int(akeep%rptr(node+1)-akeep%rptr(node))
    n = akeep%sptr(node+1)-akeep%sptr(node)
    do jj = m-n+1, m
       compute_flops = compute_flops + jj**2
    end do
    
  end function compute_flops

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  !> @brief Print assembly tree with partitions
  subroutine spldlt_print_atree_part(akeep)
    use spral_ssids_akeep, only: ssids_akeep
    ! use spral_ssids
    implicit none

    type(ssids_akeep), intent(in) :: akeep

    integer :: num_nodes
    integer :: node
    integer :: n, m ! node sizes
    integer :: region ! region of execution for node
    integer :: i, j

    integer(long), dimension(:), allocatable :: flops
    integer(long) :: jj    
    real :: tot_weight, weight
    character(len=5) :: part_str 

    ! Count flops below each node
    allocate(flops(akeep%nnodes+1))
    flops(:) = 0
    do node = 1, akeep%nnodes
       flops(node) = flops(node) + compute_flops(akeep, node)
       j = akeep%sparent(node)
       flops(j) = flops(j) + flops(node)
       !print *, "Node ", node, "parent", j, " flops ", flops(node)
    end do

    print *, "Print atree"

    num_nodes = akeep%nnodes
    tot_weight = real(flops(akeep%nnodes))

    print *, "num_nodes: ", num_nodes

    open(2, file="atree_part.dot")

    write(2, '("graph atree {")')
    write(2, '("node [")')
    write(2, '("style=filled")')
    write(2, '("]")')

    ! Root node
    write(2, '(i5," [label=", i5,"]")')akeep%nnodes+1, akeep%nnodes+1

    do i = 1, akeep%nparts
       
       ! Execution region for part i
       region = akeep%subtree(i)%exec_loc
       ! region = mod((akeep%subtree(i)%exec_loc-1), size(akeep%topology))+1
       ! print *, "[spldlt_print_atree_part] exec_loc = ", akeep%subtree(i)%exec_loc, &
       !      ", region = ", region, "size topology = ", size(akeep%topology)
       
       if (region .eq. -1) then

          write(part_str, '(i5)')akeep%part(i)
          write(2, *)"subgraph cluster"// adjustl(trim(part_str)) // " {"
          write(2, *)"color=black"

          ! write(2, '("subgraph part", i5, " {")')akeep%part(i)

          do node = akeep%part(i), akeep%part(i+1)-1

             n = akeep%sptr(node+1) - akeep%sptr(node) 
             m = int(akeep%rptr(node+1) - akeep%rptr(node))
             weight = real(flops(node)) / tot_weight 

             ! node id
             write(2, '(i10)', advance="no") node
             write(2, '(" ")', advance="no")
             write(2, '("[")', advance="no")

             ! node info
             write(2, '("label=""")', advance="no")
             write(2, '("node:", i5,"\n")', advance="no")node
             write(2, '("m:", i5,"\n")', advance="no")m
             write(2, '("n:", i5,"\n")', advance="no")n
             write(2, '("w:", f6.2,"\n")', advance="no")100*weight
             write(2, '("""")', advance="no")
             write(2, '(" fillcolor=white")', advance="no")
             write(2, '(" style=filled")', advance="no")
             write(2, '("]")', advance="no")
             write(2, '(" ")')

             ! Parent node
             ! if(akeep%sparent(node) .ne. -1) write(2, '(i10, "--", i10)')akeep%sparent(node), node

          end do

          write(2, '("}")')

          do node = akeep%part(i), akeep%part(i+1)-1
             if(akeep%sparent(node) .ne. -1) write(2, '(i10, "--", i10)')akeep%sparent(node), node
          end do

          ! ! Contributing subtrees
          ! do j = akeep%contrib_ptr(i), akeep%contrib_ptr(i+1)-1
          !    write(2, '(i10, "--", i10)')node, akeep%part(akeep%contrib_idx(j))             
          ! end do

       else

          node = akeep%part(i+1)-1
          weight = real(flops(node)) / tot_weight 

          ! part id
          write(2, '(i10)', advance="no") node 
          write(2, '(" ")', advance="no")
          write(2, '("[")', advance="no")
          
          ! part info
          write(2, '("label=""")', advance="no")
          write(2, '("part:", i5,"\n")', advance="no")i
          write(2, '("node sa:", i5,"\n")', advance="no")akeep%part(i)
          write(2, '("node en:", i5,"\n")', advance="no")akeep%part(i+1)-1
          write(2, '("region:", i5,"\n")', advance="no")region
          write(2, '("w:", f6.2,"\n")', advance="no")100*weight
          write(2, '("""")', advance="no")
          write(2, '(" fillcolor=lightgrey")', advance="no")
          write(2, '(" style=filled")', advance="no")
          write(2, '("]")', advance="no")
          write(2, '(" ")')

          ! Parent node
          if(akeep%sparent(node) .ne. -1) write(2, '(i10, "--", i10)')akeep%sparent(node), node
          
       end if
       
    end do

    write(2, '("}")')

    close(2)

  end subroutine spldlt_print_atree_part

end module spldlt_analyse_mod
